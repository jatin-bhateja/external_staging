diff --git a/configure b/configure
old mode 100644
new mode 100755
diff --git a/src/hotspot/cpu/x86/c2_MacroAssembler_x86.cpp b/src/hotspot/cpu/x86/c2_MacroAssembler_x86.cpp
index 26c19ee6f1d..2996bafe6b9 100644
--- a/src/hotspot/cpu/x86/c2_MacroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c2_MacroAssembler_x86.cpp
@@ -1211,6 +1211,55 @@ void C2_MacroAssembler::vextendwd(bool sign, XMMRegister dst, XMMRegister src, i
   }
 }
 
+void C2_MacroAssembler::vprotate_byte_lanes_imm(int opcode, XMMRegister dst, XMMRegister src,
+                                                XMMRegister tmp, int lshift, int rshift, int vector_len) {
+  assert((lshift + rshift) == 8, "");
+  assert(VectorNode::is_vector_rotate(opcode), "");
+  vextendbw(false, tmp, src, vector_len);
+  vpsllw(dst, tmp, lshift, vector_len);
+  vpsrlw(tmp, tmp, rshift, vector_len);
+  vpor(dst, dst, tmp, vector_len);
+}
+
+void C2_MacroAssembler::vprotate_byte_imm_avx(int opcode, XMMRegister dst, XMMRegister src, XMMRegister tmp1,
+                                              XMMRegister tmp2, XMMRegister tmp3, int shift, int vector_len) {
+  assert(shift < 8, "");
+  if (opcode == Op_RotateLeftV) {
+    //if (vector_len == Assembler::AVX_128bit) {
+      vprotate_byte_lanes_imm(opcode, dst, src, tmp1, shift, 8 - shift, Assembler::AVX_256bit);
+      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), Assembler::AVX_256bit, noreg);
+      vextracti128_high(tmp1, dst);
+      vpackuswb(dst, dst, tmp1, vector_len);
+    /*} else if (vector_len == Assembler::AVX_256bit) {
+      vprotate_byte_lanes_imm(opcode, dst, src, tmp1, shift, 8 - shift, vector_len);
+      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), vector_len, noreg);
+      vextracti128_high(tmp1, dst);
+      vpackuswb(dst, dst, tmp1, vector_len);
+      vextracti128_high(tmp1, src);
+      vprotate_byte_lanes_imm(opcode, tmp3, tmp1, tmp2, shift, 8 - shift, vector_len);
+      vpand(tmp3, tmp3, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), vector_len, noreg);
+      vextracti128_high(tmp1, tmp3);
+      vpackuswb(tmp3, tmp3, tmp1, vector_len);
+      vinserti128(dst, dst, tmp3, 1);
+    } else if (vector_len == Assembler::AVX_512bit) {
+      vprotate_byte_lanes_imm(opcode, dst, src, tmp1, shift, 8 - shift, vector_len);
+      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), vector_len, noreg);
+      vpermq(dst, dst, 0xd8, vector_len);
+      vextracti64x4_high(tmp1, dst);
+      vpackuswb(dst, dst, tmp1, vector_len);
+      vextracti64x4_high(tmp1, src);
+      vprotate_byte_lanes_imm(opcode, tmp3, tmp1, tmp2, shift, 8 - shift, vector_len);
+      vpand(tmp3, tmp3, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), vector_len, noreg);
+      vpermq(tmp3, tmp3, 0xd8, vector_len);
+      vextracti64x4_high(tmp1, tmp3);
+      vpackuswb(tmp3, tmp3, tmp1, vector_len);
+      vinserti64x4(dst, dst, tmp3, 1);
+    }*/
+  } else {
+    assert(opcode == Op_RotateRightV, "");
+  }
+}
+
 void C2_MacroAssembler::vprotate_imm(int opcode, BasicType etype, XMMRegister dst, XMMRegister src,
                                      int shift, int vector_len) {
   if (opcode == Op_RotateLeftV) {
diff --git a/src/hotspot/cpu/x86/c2_MacroAssembler_x86.hpp b/src/hotspot/cpu/x86/c2_MacroAssembler_x86.hpp
index 029918a4f36..c0a01c8bde8 100644
--- a/src/hotspot/cpu/x86/c2_MacroAssembler_x86.hpp
+++ b/src/hotspot/cpu/x86/c2_MacroAssembler_x86.hpp
@@ -115,6 +115,10 @@ public:
 
   void vprotate_imm(int opcode, BasicType etype, XMMRegister dst, XMMRegister src, int shift, int vector_len);
   void vprotate_var(int opcode, BasicType etype, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len);
+  void vprotate_byte_lanes_imm(int opcode, XMMRegister dst, XMMRegister src,
+                               XMMRegister tmp, int lshift, int rshift, int vector_len);
+  void vprotate_byte_imm_avx(int opcode, XMMRegister dst, XMMRegister src, XMMRegister tmp1, XMMRegister tmp2,
+                             XMMRegister tmp3, int shift, int vector_len);
 
   void varshiftd(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vlen_enc);
   void varshiftw(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vlen_enc);
diff --git a/src/hotspot/cpu/x86/x86.ad b/src/hotspot/cpu/x86/x86.ad
index f00f32c7593..8afc7a65ae5 100644
--- a/src/hotspot/cpu/x86/x86.ad
+++ b/src/hotspot/cpu/x86/x86.ad
@@ -1751,7 +1751,7 @@ const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType
       break;
     case Op_RotateRightV:
     case Op_RotateLeftV:
-      if (bt != T_INT && bt != T_LONG) {
+      if (bt != T_INT && bt != T_LONG && !(bt == T_BYTE && size_in_bits == 128)) {
         return false;
       } // fallthrough
     case Op_MacroLogicV:
@@ -2075,7 +2075,7 @@ const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, Bas
     case Op_XorV:
     case Op_RotateRightV:
     case Op_RotateLeftV:
-      if (bt != T_INT && bt != T_LONG) {
+      if (bt != T_INT && bt != T_LONG && !(bt == T_BYTE && size_in_bits == 128)) {
         return false; // Implementation limitation
       }
       return true;
@@ -9056,7 +9056,39 @@ instruct vpternlog_mem(vec dst, vec src2, memory src3, immU8 func) %{
 %}
 
 // --------------------------------- Rotation Operations ----------------------------------
+
+instruct vprotate_byte_immI8_16B(vec dst, vec src, immI8 shift, vec tmp) %{
+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE &&
+            Matcher::vector_length_in_bytes(n) <= 16);
+  match(Set dst (RotateLeftV src shift));
+  effect(TEMP tmp);
+  format %{ "vprotate_byte_imm8 $dst,$src,$shift\t! using $tmp as TEMP" %}
+  ins_encode %{
+    int opcode      = this->ideal_Opcode();
+    int vector_len  = vector_length_encoding(this);
+    __ vprotate_byte_imm_avx(opcode, $dst$$XMMRegister, $src$$XMMRegister,
+                             $tmp$$XMMRegister, xnoreg, xnoreg, $shift$$constant, vector_len);
+  %}
+  ins_pipe( pipe_slow );
+%}
+
+//instruct vprotate_byte_immI8_GT16B(vec dst, vec src, immI8 shift, vec tmp1, vec tmp2, vec tmp3) %{
+//  predicate(Matcher::vector_element_basic_type(n) == T_BYTE &&
+//            Matcher::vector_length_in_bytes(n) > 16);
+//  match(Set dst (RotateLeftV src shift));
+//  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3);
+//  format %{ "vprotate_byte_imm8 $dst,$src,$shift\t! using $tmp1, $tmp2 and $tmp3 as TEMP" %}
+//  ins_encode %{
+//    int opcode      = this->ideal_Opcode();
+//    int vector_len  = vector_length_encoding(this);
+//    __ vprotate_byte_imm_avx(opcode, $dst$$XMMRegister, $src$$XMMRegister, $tmp1$$XMMRegister,
+//                             $tmp2$$XMMRegister, $tmp3$$XMMRegister, $shift$$constant, vector_len);
+//  %}
+//  ins_pipe( pipe_slow );
+//%}
+
 instruct vprotate_immI8(vec dst, vec src, immI8 shift) %{
+  predicate(Matcher::vector_element_basic_type(n) != T_BYTE || Matcher::vector_length_in_bytes(n) > 16);
   match(Set dst (RotateLeftV src shift));
   match(Set dst (RotateRightV src shift));
   format %{ "vprotate_imm8 $dst,$src,$shift\t! vector rotate" %}
@@ -9070,6 +9102,7 @@ instruct vprotate_immI8(vec dst, vec src, immI8 shift) %{
 %}
 
 instruct vprorate(vec dst, vec src, vec shift) %{
+  predicate(Matcher::vector_element_basic_type(n) != T_BYTE || Matcher::vector_length_in_bytes(n) > 16);
   match(Set dst (RotateLeftV src shift));
   match(Set dst (RotateRightV src shift));
   format %{ "vprotate $dst,$src,$shift\t! vector rotate" %}
