diff --git a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
index 7284cfb2ca7..84b453b87de 100644
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -6214,6 +6214,37 @@ int MacroAssembler::extend_stack_for_inline_args(int args_on_stack) {
   return sp_inc;
 }
 
+void MacroAssembler::check_params_in_larval_state(BasicType* sig_bt, VMRegPair* regs, int args_passed) {
+  for (int i = 0; i < args_passed; i++) {
+    if (sig_bt[i] == T_OBJECT) {
+      Label not_larval;
+      push(rax);
+      if (regs[i]->is_reg()) {
+        int oop_reg  = regs[i]->as_Register();
+        movptr(rax, Address(oop_reg, oopDesc::mark_offset_in_bytes()));
+        andptr(rax, 1 << markWord::larval_shift);
+        jccb(Assembler::equal, not_larval);
+        push(rax);
+        movl(c_arg0, Deoptimization::make_trap_request(Deoptimization::Reason_lraval_state_param, Deoptimization::Action_none));
+        call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::uncommon_trap_blob()->entry_point())));
+      } else {
+        assert(regs[i]->is_stack(), "");
+        int oop_st_off = regs[i]->reg2stack() * VMRegImpl::stack_slot_size + wordSize;
+        movptr(rax, Address(rsp, oop_st_off));
+        movptr(rax, Address(rax, oopDesc::mark_offset_in_bytes()));
+        andptr(rax, 1 << markWord::larval_shift);
+        jccb(Assembler::equal, not_larval);
+        push(rax);
+        movl(c_arg0, Deoptimization::make_trap_request(Deoptimization::Reason_lraval_state_param, Deoptimization::Action_none));
+        call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::uncommon_trap_blob()->entry_point())));
+      }
+      bind(not_larval);
+      pop(rax);
+    }
+  }
+}
+
+
 // Read all fields from an inline type buffer and store the field values in registers/stack slots.
 bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index,
                                           VMReg from, int& from_index, VMRegPair* to, int to_count, int& to_index,
diff --git a/src/hotspot/cpu/x86/macroAssembler_x86.hpp b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
index 7b1a7addcac..5a5d9082eaf 100644
--- a/src/hotspot/cpu/x86/macroAssembler_x86.hpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
@@ -137,6 +137,8 @@ class MacroAssembler: public Assembler {
   void test_null_free_array_layout(Register lh, Label& is_null_free_array);
   void test_non_null_free_array_layout(Register lh, Label& is_non_null_free_array);
 
+  void check_params_in_larval_state(BasicType* sig_bt, VMRegPair* regs, int args_passed);
+
   // Required platform-specific helpers for Label::patch_instructions.
   // They _shadow_ the declarations in AbstractAssembler, which are undefined.
   void pd_patch_instruction(address branch, address target, const char* file, int line) {
diff --git a/src/hotspot/share/asm/macroAssembler_common.cpp b/src/hotspot/share/asm/macroAssembler_common.cpp
index 97fd91785b3..bef3444fe3b 100644
--- a/src/hotspot/share/asm/macroAssembler_common.cpp
+++ b/src/hotspot/share/asm/macroAssembler_common.cpp
@@ -124,6 +124,8 @@ int MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {
   VMRegPair* regs = NEW_RESOURCE_ARRAY(VMRegPair, args_passed);
   int args_on_stack = SharedRuntime::java_calling_convention(sig_bt, regs, args_passed);
 
+  check_params_in_larval_state(sig_bt, regs, args_passed);
+
   // Get scalarized calling convention
   int args_passed_cc = SigEntry::fill_sig_bt(sig, sig_bt);
   VMRegPair* regs_cc = NEW_RESOURCE_ARRAY(VMRegPair, sig->length());
diff --git a/src/hotspot/share/opto/callGenerator.cpp b/src/hotspot/share/opto/callGenerator.cpp
index ba8b3cd88d3..74fec0097b5 100644
--- a/src/hotspot/share/opto/callGenerator.cpp
+++ b/src/hotspot/share/opto/callGenerator.cpp
@@ -156,9 +156,22 @@ JVMState* DirectCallGenerator::generate(JVMState* jvms) {
   GraphKit kit(jvms);
   kit.C->print_inlining_update(this);
   PhaseGVN& gvn = kit.gvn();
+  bool is_larval_args = check_larval_arguments_for_java_call(tf()); 
   bool is_static = method()->is_static();
-  address target = is_static ? SharedRuntime::get_resolve_static_call_stub()
-                             : SharedRuntime::get_resolve_opt_virtual_call_stub();
+  address target = nullptr;
+  if (is_static) {
+    if (is_larval_args) {
+      target = SharedRuntime::get_resolve_static_call_larval_args_stub();
+    } else {
+      target = SharedRuntime::get_resolve_static_call_stub();
+    }
+  } else {
+    if (is_larval_args) {
+      target = SharedRuntime::get_resolve_opt_virtual_call_larval_args_stub();
+    } else {
+      target = SharedRuntime::get_resolve_opt_virtual_call_stub();
+    }
+  }
 
   if (kit.C->log() != nullptr) {
     kit.C->log()->elem("direct_call bci='%d'", jvms->bci());
diff --git a/src/hotspot/share/opto/graphKit.cpp b/src/hotspot/share/opto/graphKit.cpp
index f2f3fa384c1..0bc164546a7 100644
--- a/src/hotspot/share/opto/graphKit.cpp
+++ b/src/hotspot/share/opto/graphKit.cpp
@@ -1839,6 +1839,22 @@ Node* GraphKit::load_array_element(Node* ary, Node* idx, const TypeAryPtr* aryty
   return ld;
 }
 
+bool GraphKit::check_larval_arguments_for_java_call(TypeFunc* tf) {
+  const TypeTuple* domain = tf()->domain_sig();
+  int nargs = domain->cnt();
+  for (uint i = TypeFunc::Parms, idx = TypeFunc::Parms; i < nargs; i++) {
+    Node* arg = argument(i-TypeFunc::Parms);
+    const Type* t = domain->field_at(i);
+    if (t->is_inlinetypeptr()) {
+      AllocateNode* alloc = AllocateNode::Ideal_allocation(arg);
+      if (alloc && alloc->_larval) {
+        return true;
+      }      
+    }
+  }
+  return false;
+}
+
 //-------------------------set_arguments_for_java_call-------------------------
 // Arguments (pre-popped from the stack) are taken from the JVMS.
 void GraphKit::set_arguments_for_java_call(CallJavaNode* call, bool is_late_inline) {
diff --git a/src/hotspot/share/opto/graphKit.hpp b/src/hotspot/share/opto/graphKit.hpp
index c1789be7f03..f91a242d42e 100644
--- a/src/hotspot/share/opto/graphKit.hpp
+++ b/src/hotspot/share/opto/graphKit.hpp
@@ -718,6 +718,9 @@ class GraphKit : public Phase {
   // (The next step is to call set_edges_for_java_call.)
   void  set_arguments_for_java_call(CallJavaNode* call, bool is_late_inline = false);
 
+  // Checks if any argument passed to method call is a value object in larval state.
+  bool check_larval_arguments_for_java_call(TypeFunc* tf);
+
   // Fill in non-argument edges for the call.
   // Transform the call, and update the basics: control, i_o, memory.
   // (The next step is usually to call set_results_for_java_call.)
diff --git a/src/hotspot/share/runtime/deoptimization.hpp b/src/hotspot/share/runtime/deoptimization.hpp
index 228d8642f9f..3421af2bdb0 100644
--- a/src/hotspot/share/runtime/deoptimization.hpp
+++ b/src/hotspot/share/runtime/deoptimization.hpp
@@ -124,6 +124,7 @@ class Deoptimization : AllStatic {
     Reason_unresolved,
     Reason_jsr_mismatch,
 #endif
+    Reason_lraval_state_param,   // suppress scalarization for incoming larval parameters.
 
     // Used to define MethodData::_trap_hist_limit where Reason_tenured isn't included
     Reason_TRAP_HISTORY_LENGTH,
diff --git a/src/hotspot/share/runtime/sharedRuntime.cpp b/src/hotspot/share/runtime/sharedRuntime.cpp
index caeea7192a5..ce7635d3c82 100644
--- a/src/hotspot/share/runtime/sharedRuntime.cpp
+++ b/src/hotspot/share/runtime/sharedRuntime.cpp
@@ -94,6 +94,9 @@ RuntimeStub*        SharedRuntime::_ic_miss_blob;
 RuntimeStub*        SharedRuntime::_resolve_opt_virtual_call_blob;
 RuntimeStub*        SharedRuntime::_resolve_virtual_call_blob;
 RuntimeStub*        SharedRuntime::_resolve_static_call_blob;
+RuntimeStub*        SharedRuntime::_resolve_opt_virtual_call_larval_args_blob;
+RuntimeStub*        SharedRuntime::_resolve_virtual_call_larval_args_blob
+RuntimeStub*        SharedRuntime::_resolve_static_call_larval_args_blob
 
 DeoptimizationBlob* SharedRuntime::_deopt_blob;
 SafepointBlob*      SharedRuntime::_polling_page_vectors_safepoint_handler_blob;
@@ -114,6 +117,9 @@ void SharedRuntime::generate_stubs() {
   _resolve_opt_virtual_call_blob       = generate_resolve_blob(CAST_FROM_FN_PTR(address, SharedRuntime::resolve_opt_virtual_call_C),   "resolve_opt_virtual_call");
   _resolve_virtual_call_blob           = generate_resolve_blob(CAST_FROM_FN_PTR(address, SharedRuntime::resolve_virtual_call_C),       "resolve_virtual_call");
   _resolve_static_call_blob            = generate_resolve_blob(CAST_FROM_FN_PTR(address, SharedRuntime::resolve_static_call_C),        "resolve_static_call");
+  _resolve_opt_virtual_call_larval_args_blob  = generate_resolve_blob(CAST_FROM_FN_PTR(address, SharedRuntime::resolve_opt_virtual_call_larval_args_C), "resolve_opt_virtual_call_larval_args_C");
+  _resolve_virtual_call_larval_args_blob = generate_resolve_blob(CAST_FROM_FN_PTR(address, SharedRuntime::resolve_virtual_call_larval_args_C), "resolve_virtual_call");
+  _resolve_static_call_larval_args_blob  = generate_resolve_blob(CAST_FROM_FN_PTR(address, SharedRuntime::resolve_static_call_larval_args_C), "resolve_static_call");
 
   AdapterHandlerLibrary::initialize();
 
@@ -1653,9 +1659,78 @@ JRT_BLOCK_ENTRY(address, SharedRuntime::handle_wrong_method_abstract(JavaThread*
   return res;
 JRT_END
 
+// resolve a static call and patch code
+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_static_call_larval_args_C(JavaThread* current))
+  methodHandle callee_method;
+  bool caller_is_c1 = false;
+  bool enter_special = false;
+  JRT_BLOCK
+    callee_method = SharedRuntime::resolve_helper(false, false, caller_is_c1, CHECK_NULL);
+    current->set_vm_result_2(callee_method());
+
+    if (current->is_interp_only_mode()) {
+      RegisterMap reg_map(current,
+                          RegisterMap::UpdateMap::skip,
+                          RegisterMap::ProcessFrames::include,
+                          RegisterMap::WalkContinuation::skip);
+      frame stub_frame = current->last_frame();
+      assert(stub_frame.is_runtime_frame(), "must be a runtimeStub");
+      frame caller = stub_frame.sender(&reg_map);
+      enter_special = caller.cb() != nullptr && caller.cb()->is_compiled()
+        && caller.cb()->as_compiled_method()->method()->is_continuation_enter_intrinsic();
+    }
+  JRT_BLOCK_END
+
+  if (current->is_interp_only_mode() && enter_special) {
+    // enterSpecial is compiled and calls this method to resolve the call to Continuation::enter
+    // but in interp_only_mode we need to go to the interpreted entry
+    // The c2i won't patch in this mode -- see fixup_callers_callsite
+    //
+    // This should probably be done in all cases, not just enterSpecial (see JDK-8218403),
+    // but that's part of a larger fix, and the situation is worse for enterSpecial, as it has no
+    // interpreted version.
+    return callee_method->get_c2i_entry();
+  }
+
+  // return compiled code entry point after potential safepoints
+  address entry = callee_method->verified_inline_code_entry();
+  assert(entry != nullptr, "Jump to zero!");
+  return entry;
+JRT_END
+
+
+// resolve virtual call and update inline cache to monomorphic
+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_virtual_call_larval_args_C(JavaThread* current))
+  methodHandle callee_method;
+  bool caller_is_c1 = false;
+  JRT_BLOCK
+    callee_method = SharedRuntime::resolve_helper(true, false, caller_is_c1, CHECK_NULL);
+    current->set_vm_result_2(callee_method());
+  JRT_BLOCK_END
+  // return compiled code entry point after potential safepoints
+  address entry = callee_method->verified_inline_code_entry();
+  assert(entry != nullptr, "Jump to zero!");
+  return entry;
+JRT_END
+
+
+// Resolve a virtual call that can be statically bound (e.g., always
+// monomorphic, so it has no inline cache).  Patch code to resolved target.
+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_opt_virtual_call_larval_args_C(JavaThread* current))
+  methodHandle callee_method;
+  bool caller_is_c1 = false;
+  JRT_BLOCK
+    callee_method = SharedRuntime::resolve_helper(true, true, caller_is_c1, CHECK_NULL);
+    current->set_vm_result_2(callee_method());
+  JRT_BLOCK_END
+  // return compiled code entry point after potential safepoints
+  address entry = callee_method->verified_inline_code_entry();
+  assert(entry != nullptr, "Jump to zero!");
+  return entry;
+JRT_END
 
 // resolve a static call and patch code
-JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_static_call_C(JavaThread* current ))
+JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_static_call_C(JavaThread* current))
   methodHandle callee_method;
   bool caller_is_c1 = false;
   bool enter_special = false;
@@ -1688,7 +1763,7 @@ JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_static_call_C(JavaThread* curren
   }
 
   // return compiled code entry point after potential safepoints
-  address entry = caller_is_c1 ?
+  address entry = caller_is_c1 || force_inline_entry ?
     callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();
   assert(entry != nullptr, "Jump to zero!");
   return entry;
@@ -1704,7 +1779,7 @@ JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_virtual_call_C(JavaThread* curre
     current->set_vm_result_2(callee_method());
   JRT_BLOCK_END
   // return compiled code entry point after potential safepoints
-  address entry = caller_is_c1 ?
+  address entry = caller_is_c1  || force_inline_entry ?
     callee_method->verified_inline_code_entry() : callee_method->verified_inline_ro_code_entry();
   assert(entry != nullptr, "Jump to zero!");
   return entry;
@@ -1721,7 +1796,7 @@ JRT_BLOCK_ENTRY(address, SharedRuntime::resolve_opt_virtual_call_C(JavaThread* c
     current->set_vm_result_2(callee_method());
   JRT_BLOCK_END
   // return compiled code entry point after potential safepoints
-  address entry = caller_is_c1 ?
+  address entry = caller_is_c1 || force_inline_entry ?
     callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();
   assert(entry != nullptr, "Jump to zero!");
   return entry;
diff --git a/src/hotspot/share/runtime/sharedRuntime.hpp b/src/hotspot/share/runtime/sharedRuntime.hpp
index 8a34ae5426e..04bca704b8b 100644
--- a/src/hotspot/share/runtime/sharedRuntime.hpp
+++ b/src/hotspot/share/runtime/sharedRuntime.hpp
@@ -246,6 +246,18 @@ class SharedRuntime: AllStatic {
     assert(_resolve_static_call_blob != nullptr, "oops");
     return _resolve_static_call_blob->entry_point();
   }
+  static address get_resolve_opt_virtual_call_larval_args_stub() {
+    assert(_resolve_opt_virtual_call_larval_args_blob != nullptr, "oops");
+    return _resolve_opt_virtual_call_larval_args_blob->entry_point();
+  }
+  static address get_resolve_virtual_call_larval_args_stub() {
+    assert(_resolve_virtual_call_larval_args_blob != nullptr, "oops");
+    return _resolve_virtual_call_larval_args_blob->entry_point();
+  }
+  static address get_resolve_static_call_larval_args_stub() {
+    assert(_resolve_static_call_larval_args_blob != nullptr, "oops");
+    return _resolve_static_call_larval_args_blob->entry_point();
+  }
 
   static SafepointBlob* polling_page_return_handler_blob()     { return _polling_page_return_handler_blob; }
   static SafepointBlob* polling_page_safepoint_handler_blob()  { return _polling_page_safepoint_handler_blob; }
