Pass Arguments:  -tti -targetlibinfo -tbaa -scoped-noalias -assumption-cache-tracker -verify -ee-instrument -simplifycfg -domtree -sroa -early-cse -lower-expect
Target Transform Information
Target Library Information
Type-Based Alias Analysis
Scoped NoAlias Alias Analysis
Assumption Cache Tracker
  FunctionPass Manager
    Module Verifier
    Print Function IR
    Instrument function entry/exit with calls to e.g. mcount() (pre inlining)
    Print Function IR
    Simplify the CFG
    Print Function IR
    Dominator Tree Construction
    SROA
    Print Function IR
    Early CSE
    Print Function IR
    Lower 'expect' Intrinsics
    Print Function IR
*** IR Dump After Module Verifier ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  %init.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %init, i32* %init.addr, align 4, !tbaa !2
  %0 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %0) #3
  store i32 0, i32* %i, align 4, !tbaa !2
  store i32 0, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %entry
  %1 = load i32, i32* %i, align 4, !tbaa !2
  %cmp = icmp slt i32 %1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %2 = load i32, i32* %i, align 4, !tbaa !2
  %idxprom = sext i32 %2 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %3 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %4 = load i32, i32* %init.addr, align 4, !tbaa !2
  %add = add nsw i32 %3, %4
  %5 = load i32, i32* %i, align 4, !tbaa !2
  %add1 = add nsw i32 %5, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.inc

for.inc:                                          ; preds = %for.body
  %6 = load i32, i32* %i, align 4, !tbaa !2
  %inc = add nsw i32 %6, 1
  store i32 %inc, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %7 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  %8 = bitcast i32* %i to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %8) #3
  ret i32 %7
}
*** IR Dump After Instrument function entry/exit with calls to e.g. mcount() (pre inlining) ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  %init.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %init, i32* %init.addr, align 4, !tbaa !2
  %0 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %0) #3
  store i32 0, i32* %i, align 4, !tbaa !2
  store i32 0, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %entry
  %1 = load i32, i32* %i, align 4, !tbaa !2
  %cmp = icmp slt i32 %1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %2 = load i32, i32* %i, align 4, !tbaa !2
  %idxprom = sext i32 %2 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %3 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %4 = load i32, i32* %init.addr, align 4, !tbaa !2
  %add = add nsw i32 %3, %4
  %5 = load i32, i32* %i, align 4, !tbaa !2
  %add1 = add nsw i32 %5, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.inc

for.inc:                                          ; preds = %for.body
  %6 = load i32, i32* %i, align 4, !tbaa !2
  %inc = add nsw i32 %6, 1
  store i32 %inc, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %7 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  %8 = bitcast i32* %i to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %8) #3
  ret i32 %7
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  %init.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %init, i32* %init.addr, align 4, !tbaa !2
  %0 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %0) #3
  store i32 0, i32* %i, align 4, !tbaa !2
  store i32 0, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %1 = load i32, i32* %i, align 4, !tbaa !2
  %cmp = icmp slt i32 %1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %2 = load i32, i32* %i, align 4, !tbaa !2
  %idxprom = sext i32 %2 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %3 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %4 = load i32, i32* %init.addr, align 4, !tbaa !2
  %add = add nsw i32 %3, %4
  %5 = load i32, i32* %i, align 4, !tbaa !2
  %add1 = add nsw i32 %5, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %6 = load i32, i32* %i, align 4, !tbaa !2
  %inc = add nsw i32 %6, 1
  store i32 %inc, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %7 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  %8 = bitcast i32* %i to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %8) #3
  ret i32 %7
}
*** IR Dump After SROA ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %inc = add nsw i32 %i.0, 1
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Early CSE ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Lower 'expect' Intrinsics ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Module Verifier ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  %retval = alloca i32, align 4
  %index = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 0, i32* %retval, align 4
  %0 = bitcast i32* %index to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %0) #3
  store i32 0, i32* %index, align 4, !tbaa !2
  %1 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %1) #3
  store i32 0, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %entry
  %2 = load i32, i32* %i, align 4, !tbaa !2
  %cmp = icmp slt i32 %2, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %3 = bitcast i32* %i to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %3) #3
  br label %for.end

for.body:                                         ; preds = %for.cond
  %4 = load i32, i32* %i, align 4, !tbaa !2
  %call = call i32 @workload(i32 %4)
  %5 = load i32, i32* %index, align 4, !tbaa !2
  %add = add nsw i32 %5, %call
  store i32 %add, i32* %index, align 4, !tbaa !2
  br label %for.inc

for.inc:                                          ; preds = %for.body
  %6 = load i32, i32* %i, align 4, !tbaa !2
  %inc = add nsw i32 %6, 1
  store i32 %inc, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond.cleanup
  %7 = load i32, i32* %index, align 4, !tbaa !2
  %and = and i32 %7, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %8 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %9 = bitcast i32* %index to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %9) #3
  ret i32 %8
}
*** IR Dump After Instrument function entry/exit with calls to e.g. mcount() (pre inlining) ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  %retval = alloca i32, align 4
  %index = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 0, i32* %retval, align 4
  %0 = bitcast i32* %index to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %0) #3
  store i32 0, i32* %index, align 4, !tbaa !2
  %1 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %1) #3
  store i32 0, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.cond:                                         ; preds = %for.inc, %entry
  %2 = load i32, i32* %i, align 4, !tbaa !2
  %cmp = icmp slt i32 %2, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %3 = bitcast i32* %i to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %3) #3
  br label %for.end

for.body:                                         ; preds = %for.cond
  %4 = load i32, i32* %i, align 4, !tbaa !2
  %call = call i32 @workload(i32 %4)
  %5 = load i32, i32* %index, align 4, !tbaa !2
  %add = add nsw i32 %5, %call
  store i32 %add, i32* %index, align 4, !tbaa !2
  br label %for.inc

for.inc:                                          ; preds = %for.body
  %6 = load i32, i32* %i, align 4, !tbaa !2
  %inc = add nsw i32 %6, 1
  store i32 %inc, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond.cleanup
  %7 = load i32, i32* %index, align 4, !tbaa !2
  %and = and i32 %7, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %8 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %9 = bitcast i32* %index to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %9) #3
  ret i32 %8
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  %retval = alloca i32, align 4
  %index = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 0, i32* %retval, align 4
  %0 = bitcast i32* %index to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %0) #3
  store i32 0, i32* %index, align 4, !tbaa !2
  %1 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %1) #3
  store i32 0, i32* %i, align 4, !tbaa !2
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %2 = load i32, i32* %i, align 4, !tbaa !2
  %cmp = icmp slt i32 %2, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %3 = bitcast i32* %i to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %3) #3
  %4 = load i32, i32* %index, align 4, !tbaa !2
  %and = and i32 %4, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %5 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %6 = bitcast i32* %index to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %6) #3
  ret i32 %5

for.body:                                         ; preds = %for.cond
  %7 = load i32, i32* %i, align 4, !tbaa !2
  %call = call i32 @workload(i32 %7)
  %8 = load i32, i32* %index, align 4, !tbaa !2
  %add = add nsw i32 %8, %call
  store i32 %add, i32* %index, align 4, !tbaa !2
  %9 = load i32, i32* %i, align 4, !tbaa !2
  %inc = add nsw i32 %9, 1
  store i32 %inc, i32* %i, align 4, !tbaa !2
  br label %for.cond
}
*** IR Dump After SROA ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Early CSE ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Lower 'expect' Intrinsics ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}
Pass Arguments:  -tti -targetlibinfo -tbaa -scoped-noalias -assumption-cache-tracker -profile-summary-info -forceattrs -inferattrs -domtree -callsite-splitting -ipsccp -called-value-propagation -attributor -globalopt -domtree -mem2reg -deadargelim -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -simplifycfg -basiccg -globals-aa -prune-eh -inline -functionattrs -argpromotion -domtree -sroa -basicaa -aa -memoryssa -early-cse-memssa -basicaa -aa -lazy-value-info -jump-threading -correlated-propagation -simplifycfg -domtree -aggressive-instcombine -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -libcalls-shrinkwrap -loops -branch-prob -block-freq -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -pgo-memop-opt -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -tailcallelim -simplifycfg -reassociate -domtree -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -loop-rotate -licm -loop-unswitch -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -indvars -loop-idiom -loop-deletion -loop-unroll -mldst-motion -phi-values -basicaa -aa -memdep -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -gvn -phi-values -basicaa -aa -memdep -memcpyopt -sccp -demanded-bits -bdce -basicaa -aa -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -lazy-value-info -jump-threading -correlated-propagation -basicaa -aa -phi-values -memdep -dse -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -licm -postdomtree -adce -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -barrier -elim-avail-extern -basiccg -rpo-functionattrs -globalopt -globaldce -basiccg -globals-aa -float2int -domtree -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -loop-rotate -loop-accesses -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -loop-distribute -branch-prob -block-freq -scalar-evolution -basicaa -aa -loop-accesses -demanded-bits -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -loop-vectorize -loop-simplify -scalar-evolution -aa -loop-accesses -lazy-branch-prob -lazy-block-freq -loop-load-elim -basicaa -aa -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -simplifycfg -domtree -loops -scalar-evolution -basicaa -aa -demanded-bits -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -slp-vectorizer -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -loop-unroll -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -licm -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -transform-warning -alignment-from-assumptions -strip-dead-prototypes -globaldce -constmerge -domtree -loops -branch-prob -block-freq -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -block-freq -loop-sink -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instsimplify -div-rem-pairs -simplifycfg
Target Transform Information
Target Library Information
Type-Based Alias Analysis
Scoped NoAlias Alias Analysis
Assumption Cache Tracker
Profile summary info
  ModulePass Manager
    Force set function attributes
    Print Module IR
    Infer set function attributes
    Print Module IR
    FunctionPass Manager
      Dominator Tree Construction
      Call-site splitting
      Print Function IR
    Interprocedural Sparse Conditional Constant Propagation
      Unnamed pass: implement Pass::getPassName()
    Print Module IR
    Called Value Propagation
    Print Module IR
    Deduce and propagate attributes
    Print Module IR
    Global Variable Optimizer
      Unnamed pass: implement Pass::getPassName()
    Print Module IR
    FunctionPass Manager
      Dominator Tree Construction
      Promote Memory to Register
      Print Function IR
    Dead Argument Elimination
    Print Module IR
    FunctionPass Manager
      Dominator Tree Construction
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Natural Loop Information
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Combine redundant instructions
      Print Function IR
      Simplify the CFG
      Print Function IR
    CallGraph Construction
    Globals Alias Analysis
    Call Graph SCC Pass Manager
      Remove unused exception handling info
      Print CallGraph IR
      Function Integration/Inlining
      Print CallGraph IR
      Deduce function attributes
      Print CallGraph IR
      Promote 'by reference' arguments to scalars
      Print CallGraph IR
      FunctionPass Manager
        Dominator Tree Construction
        SROA
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Memory SSA
        Early CSE w/ MemorySSA
        Print Function IR
        Speculatively execute instructions if target has divergent branches
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Lazy Value Information Analysis
        Jump Threading
        Print Function IR
        Value Propagation
        Print Function IR
        Simplify the CFG
        Print Function IR
        Dominator Tree Construction
        Combine pattern based expressions
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Natural Loop Information
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        Combine redundant instructions
        Print Function IR
        Conditionally eliminate dead library calls
        Print Function IR
        Natural Loop Information
        Branch Probability Analysis
        Block Frequency Analysis
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        PGOMemOPSize
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Natural Loop Information
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        Tail Call Elimination
        Print Function IR
        Simplify the CFG
        Print Function IR
        Reassociate expressions
        Print Function IR
        Dominator Tree Construction
        Natural Loop Information
        Canonicalize natural loops
        Print Function IR
        LCSSA Verifier
        Print Function IR
        Loop-Closed SSA Form Pass
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Scalar Evolution Analysis
        Loop Pass Manager
          Rotate Loops
          Print Loop IR
          Loop Invariant Code Motion
          Print Loop IR
          Unswitch loops
          Print Loop IR
        Simplify the CFG
        Print Function IR
        Dominator Tree Construction
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Natural Loop Information
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        Combine redundant instructions
        Print Function IR
        Canonicalize natural loops
        Print Function IR
        LCSSA Verifier
        Print Function IR
        Loop-Closed SSA Form Pass
        Print Function IR
        Scalar Evolution Analysis
        Loop Pass Manager
          Induction Variable Simplification
          Print Loop IR
          Recognize loop idioms
          Print Loop IR
          Delete dead loops
          Print Loop IR
          Unroll loops
          Print Loop IR
        MergedLoadStoreMotion
        Print Function IR
        Phi Values Analysis
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Memory Dependence Analysis
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        Global Value Numbering
        Print Function IR
        Phi Values Analysis
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Memory Dependence Analysis
        MemCpy Optimization
        Print Function IR
        Sparse Conditional Constant Propagation
        Print Function IR
        Demanded bits analysis
        Print Function IR
        Bit-Tracking Dead Code Elimination
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        Combine redundant instructions
        Print Function IR
        Lazy Value Information Analysis
        Jump Threading
        Print Function IR
        Value Propagation
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Phi Values Analysis
        Memory Dependence Analysis
        Dead Store Elimination
        Print Function IR
        Natural Loop Information
        Canonicalize natural loops
        Print Function IR
        LCSSA Verifier
        Print Function IR
        Loop-Closed SSA Form Pass
        Print Function IR
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Scalar Evolution Analysis
        Loop Pass Manager
          Loop Invariant Code Motion
          Print Loop IR
        Post-Dominator Tree Construction
        Aggressive Dead Code Elimination
        Print Function IR
        Simplify the CFG
        Print Function IR
        Dominator Tree Construction
        Basic Alias Analysis (stateless AA impl)
        Function Alias Analysis Results
        Natural Loop Information
        Lazy Branch Probability Analysis
        Lazy Block Frequency Analysis
        Optimization Remark Emitter
        Combine redundant instructions
        Print Function IR
    A No-Op Barrier Pass
    Print Module IR
    Eliminate Available Externally Globals
    Print Module IR
    CallGraph Construction
    Deduce function attributes in RPO
    Print Module IR
    Global Variable Optimizer
      Unnamed pass: implement Pass::getPassName()
    Print Module IR
    Dead Global Elimination
    Print Module IR
    CallGraph Construction
    Globals Alias Analysis
    FunctionPass Manager
      Float to int
      Print Function IR
      Dominator Tree Construction
      Natural Loop Information
      Canonicalize natural loops
      Print Function IR
      LCSSA Verifier
      Print Function IR
      Loop-Closed SSA Form Pass
      Print Function IR
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Scalar Evolution Analysis
      Loop Pass Manager
        Rotate Loops
        Print Loop IR
      Loop Access Analysis
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Loop Distribution
      Print Function IR
      Branch Probability Analysis
      Block Frequency Analysis
      Scalar Evolution Analysis
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Loop Access Analysis
      Demanded bits analysis
      Print Function IR
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Loop Vectorization
      Print Function IR
      Canonicalize natural loops
      Print Function IR
      Scalar Evolution Analysis
      Function Alias Analysis Results
      Loop Access Analysis
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Loop Load Elimination
      Print Function IR
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Combine redundant instructions
      Print Function IR
      Simplify the CFG
      Print Function IR
      Dominator Tree Construction
      Natural Loop Information
      Scalar Evolution Analysis
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Demanded bits analysis
      Print Function IR
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      SLP Vectorizer
      Print Function IR
      Optimization Remark Emitter
      Combine redundant instructions
      Print Function IR
      Canonicalize natural loops
      Print Function IR
      LCSSA Verifier
      Print Function IR
      Loop-Closed SSA Form Pass
      Print Function IR
      Scalar Evolution Analysis
      Loop Pass Manager
        Unroll loops
        Print Loop IR
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Combine redundant instructions
      Print Function IR
      Canonicalize natural loops
      Print Function IR
      LCSSA Verifier
      Print Function IR
      Loop-Closed SSA Form Pass
      Print Function IR
      Scalar Evolution Analysis
      Loop Pass Manager
        Loop Invariant Code Motion
        Print Loop IR
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Warn about non-applied transformations
      Print Function IR
      Alignment from assumptions
      Print Function IR
    Strip Unused Function Prototypes
    Print Module IR
    Dead Global Elimination
    Print Module IR
    Merge Duplicate Global Constants
    Print Module IR
    FunctionPass Manager
      Dominator Tree Construction
      Natural Loop Information
      Branch Probability Analysis
      Block Frequency Analysis
      Canonicalize natural loops
      Print Function IR
      LCSSA Verifier
      Print Function IR
      Loop-Closed SSA Form Pass
      Print Function IR
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Scalar Evolution Analysis
      Block Frequency Analysis
      Loop Pass Manager
        Loop Sink
        Print Loop IR
      Lazy Branch Probability Analysis
      Lazy Block Frequency Analysis
      Optimization Remark Emitter
      Remove redundant instructions
      Print Function IR
      Hoist/decompose integer division and remainder
      Print Function IR
      Simplify the CFG
      Print Function IR
Pass Arguments:  -domtree
  FunctionPass Manager
    Dominator Tree Construction
Pass Arguments:  -targetlibinfo -domtree -loops -branch-prob -block-freq
Target Library Information
  FunctionPass Manager
    Dominator Tree Construction
    Natural Loop Information
    Branch Probability Analysis
    Block Frequency Analysis
Pass Arguments:  -targetlibinfo -domtree -loops -branch-prob -block-freq
Target Library Information
  FunctionPass Manager
    Dominator Tree Construction
    Natural Loop Information
    Branch Probability Analysis
    Block Frequency Analysis
*** IR Dump After Force set function attributes ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind willreturn }
attributes #2 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Infer set function attributes ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind willreturn }
attributes #2 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Call-site splitting ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Call-site splitting ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Interprocedural Sparse Conditional Constant Propagation ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind willreturn }
attributes #2 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Called Value Propagation ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind willreturn }
attributes #2 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Deduce and propagate attributes ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind uwtable
define dso_local i32 @main() #2 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind willreturn }
attributes #2 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Global Variable Optimizer ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Promote Memory to Register ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Promote Memory to Register ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Dead Argument Elimination ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp slt i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = sext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nsw i32 %i.0, 1
  %idxprom2 = sext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds ([134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 7), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp slt i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = sext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nsw i32 %i.0, 1
  br label %for.cond
}

attributes #0 = { noinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Remove unused exception handling info ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Function Integration/Inlining ***
; Function Attrs: noinline nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Deduce function attributes ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Promote 'by reference' arguments to scalars ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After SROA ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Early CSE w/ MemorySSA ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Jump Threading ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Value Propagation ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Combine pattern based expressions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Conditionally eliminate dead library calls ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After PGOMemOPSize ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Tail Call Elimination ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Reassociate expressions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %i.0 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %cmp = icmp ult i32 %i.0, 134098
  br i1 %cmp, label %for.body, label %for.end

for.body:                                         ; preds = %for.cond
  %idxprom = zext i32 %i.0 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.0, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  br label %for.cond

for.end:                                          ; preds = %for.cond
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Rotate Loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Loop Invariant Code Motion ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Unswitch loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %i.08 = phi i32 [ 0, %entry ], [ %add1, %for.body ]
  %idxprom = zext i32 %i.08 to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %add1 = add nuw nsw i32 %i.08, 1
  %idxprom2 = zext i32 %add1 to i64
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom2
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %cmp = icmp ult i32 %add1, 134098
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Induction Variable Simplification ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Recognize loop idioms ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Delete dead loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Unroll loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After MergedLoadStoreMotion ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Global Value Numbering ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 4, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After MemCpy Optimization ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 4, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Sparse Conditional Constant Propagation ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 4, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Demanded bits analysis ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 4, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Bit-Tracking Dead Code Elimination ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 4, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp ne i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Jump Threading ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Value Propagation ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Dead Store Elimination ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Loop Invariant Code Motion ***
; Preheader:
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Aggressive Dead Code Elimination ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Remove unused exception handling info ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Function Integration/Inlining ***
; Function Attrs: nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Deduce function attributes ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Promote 'by reference' arguments to scalars ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After SROA ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Early CSE w/ MemorySSA ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Jump Threading ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Value Propagation ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Combine pattern based expressions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Conditionally eliminate dead library calls ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After PGOMemOPSize ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Tail Call Elimination ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = tail call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = tail call i32 @workload(i32 %i.0)
  %add = add nsw i32 %index.0, %call
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Reassociate expressions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = tail call i32 @workload(i32 %i.0)
  %add = add nsw i32 %call, %index.0
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = tail call i32 @workload(i32 %i.0)
  %add = add nsw i32 %call, %index.0
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %and = and i32 %index.0, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = tail call i32 @workload(i32 %i.0)
  %add = add nsw i32 %call, %index.0
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.cond

for.cond:                                         ; preds = %for.body, %entry
  %index.0 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %i.0 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %cmp = icmp ult i32 %i.0, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond
  %index.0.lcssa = phi i32 [ %index.0, %for.cond ]
  %and = and i32 %index.0.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.cond
  %call = tail call i32 @workload(i32 %i.0)
  %add = add nsw i32 %call, %index.0
  %inc = add nuw nsw i32 %i.0, 1
  br label %for.cond
}
*** IR Dump After Rotate Loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %index.0.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %index.0.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Loop Invariant Code Motion ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %index.0.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %index.0.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Unswitch loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %index.0.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %index.0.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %index.0.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %index.0.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %cmp = icmp ult i32 %inc, 100000
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Induction Variable Simplification ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Recognize loop idioms ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Delete dead loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Unroll loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After MergedLoadStoreMotion ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Global Value Numbering ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup
}
*** IR Dump After MemCpy Optimization ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Sparse Conditional Constant Propagation ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Demanded bits analysis ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Bit-Tracking Dead Code Elimination ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %entry, %for.body
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp ne i32 %inc, 100000
  br i1 %exitcond, label %for.body, label %for.cond.cleanup
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Jump Threading ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Value Propagation ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Dead Store Elimination ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop Invariant Code Motion ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Aggressive Dead Code Elimination ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Remove unused exception handling info ***
Printing <null> Function
*** IR Dump After Function Integration/Inlining ***
Printing <null> Function
*** IR Dump After Deduce function attributes ***
Printing <null> Function
*** IR Dump After Promote 'by reference' arguments to scalars ***
Printing <null> Function
*** IR Dump After A No-Op Barrier Pass ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Eliminate Available Externally Globals ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Deduce function attributes in RPO ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Global Variable Optimizer ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Dead Global Elimination ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
*** IR Dump After Float to int ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Rotate Loops ***
; Preheader:
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

; Exit blocks
for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
*** IR Dump After Loop Distribution ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Demanded bits analysis ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %0 = phi i32 [ %.pre, %entry ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %0, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %1 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %1
}
*** IR Dump After Loop Vectorization ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br i1 false, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %entry
  %0 = mul i32 134080, %init
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, %.splat11
  %induction = add <8 x i32> %.splat, %1
  %2 = mul i32 %init, 8
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %vector.ph ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %index, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %induction17 = add <8 x i64> %broadcast.splat, <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>
  %induction18 = add <8 x i64> %broadcast.splat, <i64 8, i64 9, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15>
  %induction19 = add <8 x i64> %broadcast.splat, <i64 16, i64 17, i64 18, i64 19, i64 20, i64 21, i64 22, i64 23>
  %induction20 = add <8 x i64> %broadcast.splat, <i64 24, i64 25, i64 26, i64 27, i64 28, i64 29, i64 30, i64 31>
  %3 = add i64 %index, 0
  %4 = add i64 %index, 8
  %5 = add i64 %index, 16
  %6 = add i64 %index, 24
  %7 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %8 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %9 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %10 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %11 = add nuw nsw i64 %3, 1
  %12 = add nuw nsw i64 %4, 1
  %13 = add nuw nsw i64 %5, 1
  %14 = add nuw nsw i64 %6, 1
  %15 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %11
  %16 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %12
  %17 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %13
  %18 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %14
  %19 = getelementptr inbounds i32, i32* %15, i32 0
  %20 = bitcast i32* %19 to <8 x i32>*
  store <8 x i32> %7, <8 x i32>* %20, align 4, !tbaa !2
  %21 = getelementptr inbounds i32, i32* %15, i32 8
  %22 = bitcast i32* %21 to <8 x i32>*
  store <8 x i32> %8, <8 x i32>* %22, align 4, !tbaa !2
  %23 = getelementptr inbounds i32, i32* %15, i32 16
  %24 = bitcast i32* %23 to <8 x i32>*
  store <8 x i32> %9, <8 x i32>* %24, align 4, !tbaa !2
  %25 = getelementptr inbounds i32, i32* %15, i32 24
  %26 = bitcast i32* %25 to <8 x i32>*
  store <8 x i32> %10, <8 x i32>* %26, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %27 = icmp eq i64 %index.next, 134080
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !6

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 134098, 134080
  br i1 %cmp.n, label %for.end, label %scalar.ph

scalar.ph:                                        ; preds = %middle.block, %entry
  %bc.resume.val = phi i32 [ %ind.end, %middle.block ], [ %.pre, %entry ]
  %bc.resume.val9 = phi i64 [ 134080, %middle.block ], [ 0, %entry ]
  br label %for.body

for.body:                                         ; preds = %for.body, %scalar.ph
  %28 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ %bc.resume.val9, %scalar.ph ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %28, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %middle.block, %for.body
  %29 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %29
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br i1 false, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %entry
  %0 = mul i32 134080, %init
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, %.splat11
  %induction = add <8 x i32> %.splat, %1
  %2 = mul i32 %init, 8
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %vector.ph ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %index, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %induction17 = add <8 x i64> %broadcast.splat, <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>
  %induction18 = add <8 x i64> %broadcast.splat, <i64 8, i64 9, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15>
  %induction19 = add <8 x i64> %broadcast.splat, <i64 16, i64 17, i64 18, i64 19, i64 20, i64 21, i64 22, i64 23>
  %induction20 = add <8 x i64> %broadcast.splat, <i64 24, i64 25, i64 26, i64 27, i64 28, i64 29, i64 30, i64 31>
  %3 = add i64 %index, 0
  %4 = add i64 %index, 8
  %5 = add i64 %index, 16
  %6 = add i64 %index, 24
  %7 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %8 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %9 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %10 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %11 = add nuw nsw i64 %3, 1
  %12 = add nuw nsw i64 %4, 1
  %13 = add nuw nsw i64 %5, 1
  %14 = add nuw nsw i64 %6, 1
  %15 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %11
  %16 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %12
  %17 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %13
  %18 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %14
  %19 = getelementptr inbounds i32, i32* %15, i32 0
  %20 = bitcast i32* %19 to <8 x i32>*
  store <8 x i32> %7, <8 x i32>* %20, align 4, !tbaa !2
  %21 = getelementptr inbounds i32, i32* %15, i32 8
  %22 = bitcast i32* %21 to <8 x i32>*
  store <8 x i32> %8, <8 x i32>* %22, align 4, !tbaa !2
  %23 = getelementptr inbounds i32, i32* %15, i32 16
  %24 = bitcast i32* %23 to <8 x i32>*
  store <8 x i32> %9, <8 x i32>* %24, align 4, !tbaa !2
  %25 = getelementptr inbounds i32, i32* %15, i32 24
  %26 = bitcast i32* %25 to <8 x i32>*
  store <8 x i32> %10, <8 x i32>* %26, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %27 = icmp eq i64 %index.next, 134080
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !6

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 134098, 134080
  br i1 %cmp.n, label %for.end, label %scalar.ph

scalar.ph:                                        ; preds = %middle.block, %entry
  %bc.resume.val = phi i32 [ %ind.end, %middle.block ], [ %.pre, %entry ]
  %bc.resume.val9 = phi i64 [ 134080, %middle.block ], [ 0, %entry ]
  br label %for.body

for.body:                                         ; preds = %for.body, %scalar.ph
  %28 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ %bc.resume.val9, %scalar.ph ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %28, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end.loopexit, label %for.body, !llvm.loop !8

for.end.loopexit:                                 ; preds = %for.body
  br label %for.end

for.end:                                          ; preds = %for.end.loopexit, %middle.block
  %29 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %29
}
*** IR Dump After Loop Load Elimination ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br i1 false, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %entry
  %0 = mul i32 134080, %init
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, %.splat11
  %induction = add <8 x i32> %.splat, %1
  %2 = mul i32 %init, 8
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %vector.ph ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %broadcast.splatinsert = insertelement <8 x i64> undef, i64 %index, i32 0
  %broadcast.splat = shufflevector <8 x i64> %broadcast.splatinsert, <8 x i64> undef, <8 x i32> zeroinitializer
  %induction17 = add <8 x i64> %broadcast.splat, <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>
  %induction18 = add <8 x i64> %broadcast.splat, <i64 8, i64 9, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15>
  %induction19 = add <8 x i64> %broadcast.splat, <i64 16, i64 17, i64 18, i64 19, i64 20, i64 21, i64 22, i64 23>
  %induction20 = add <8 x i64> %broadcast.splat, <i64 24, i64 25, i64 26, i64 27, i64 28, i64 29, i64 30, i64 31>
  %3 = add i64 %index, 0
  %4 = add i64 %index, 8
  %5 = add i64 %index, 16
  %6 = add i64 %index, 24
  %7 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %8 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %9 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %10 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %11 = add nuw nsw i64 %3, 1
  %12 = add nuw nsw i64 %4, 1
  %13 = add nuw nsw i64 %5, 1
  %14 = add nuw nsw i64 %6, 1
  %15 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %11
  %16 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %12
  %17 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %13
  %18 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %14
  %19 = getelementptr inbounds i32, i32* %15, i32 0
  %20 = bitcast i32* %19 to <8 x i32>*
  store <8 x i32> %7, <8 x i32>* %20, align 4, !tbaa !2
  %21 = getelementptr inbounds i32, i32* %15, i32 8
  %22 = bitcast i32* %21 to <8 x i32>*
  store <8 x i32> %8, <8 x i32>* %22, align 4, !tbaa !2
  %23 = getelementptr inbounds i32, i32* %15, i32 16
  %24 = bitcast i32* %23 to <8 x i32>*
  store <8 x i32> %9, <8 x i32>* %24, align 4, !tbaa !2
  %25 = getelementptr inbounds i32, i32* %15, i32 24
  %26 = bitcast i32* %25 to <8 x i32>*
  store <8 x i32> %10, <8 x i32>* %26, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %27 = icmp eq i64 %index.next, 134080
  br i1 %27, label %middle.block, label %vector.body, !llvm.loop !6

middle.block:                                     ; preds = %vector.body
  %cmp.n = icmp eq i64 134098, 134080
  br i1 %cmp.n, label %for.end, label %scalar.ph

scalar.ph:                                        ; preds = %middle.block, %entry
  %bc.resume.val = phi i32 [ %ind.end, %middle.block ], [ %.pre, %entry ]
  %bc.resume.val9 = phi i64 [ 134080, %middle.block ], [ 0, %entry ]
  br label %for.body

for.body:                                         ; preds = %for.body, %scalar.ph
  %28 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ %bc.resume.val9, %scalar.ph ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %28, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end.loopexit, label %for.body, !llvm.loop !8

for.end.loopexit:                                 ; preds = %for.body
  br label %for.end

for.end:                                          ; preds = %for.end.loopexit, %middle.block
  %29 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %29
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  br i1 false, label %scalar.ph, label %vector.ph

vector.ph:                                        ; preds = %entry
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph
  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %vector.ph ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %middle.block, label %vector.body, !llvm.loop !6

middle.block:                                     ; preds = %vector.body
  br i1 false, label %for.end, label %scalar.ph

scalar.ph:                                        ; preds = %middle.block, %entry
  %bc.resume.val = phi i32 [ %ind.end, %middle.block ], [ %.pre, %entry ]
  %bc.resume.val9 = phi i64 [ 134080, %middle.block ], [ 0, %entry ]
  br label %for.body

for.body:                                         ; preds = %for.body, %scalar.ph
  %17 = phi i32 [ %bc.resume.val, %scalar.ph ], [ %add, %for.body ]
  %indvars.iv = phi i64 [ %bc.resume.val9, %scalar.ph ], [ %indvars.iv.next, %for.body ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end.loopexit, label %for.body, !llvm.loop !8

for.end.loopexit:                                 ; preds = %for.body
  br label %for.end

for.end:                                          ; preds = %for.end.loopexit, %middle.block
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %vector.body ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %vector.body ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After Demanded bits analysis ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %vector.body ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %vector.body ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After SLP Vectorizer ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %vector.body ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %vector.body ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %vector.body ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %vector.body ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %for.body.preheader ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %for.body.preheader ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %for.body.preheader ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %for.body.preheader ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader, %for.body
  %17 = phi i32 [ %add, %for.body ], [ %ind.end, %for.body.preheader ]
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 134080, %for.body.preheader ]
  %add = add nsw i32 %17, %init
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %arrayidx3 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %indvars.iv.next
  store i32 %add, i32* %arrayidx3, align 4, !tbaa !2
  %exitcond = icmp eq i64 %indvars.iv.next, 134098
  br i1 %exitcond, label %for.end, label %for.body, !llvm.loop !8

for.end:                                          ; preds = %for.body
  %18 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %18
}
*** IR Dump After Unroll loops ***
; Preheader:
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

; Exit blocks
for.body.preheader:                               ; preds = %vector.body
  br label %for.body
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Loop Invariant Code Motion ***
; Preheader:
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

; Exit blocks
for.body.preheader:                               ; preds = %vector.body
  br label %for.body
*** IR Dump After Warn about non-applied transformations ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Alignment from assumptions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Float to int ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Rotate Loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Loop Distribution ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Demanded bits analysis ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop Vectorization ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop Load Elimination ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Demanded bits analysis ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After SLP Vectorizer ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Unroll loops ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Combine redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop Invariant Code Motion ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Warn about non-applied transformations ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Alignment from assumptions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Strip Unused Function Prototypes ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.isvectorized", i32 1}
*** IR Dump After Dead Global Elimination ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.isvectorized", i32 1}
*** IR Dump After Merge Duplicate Global Constants ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.isvectorized", i32 1}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Loop Sink ***
; Preheader:
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

; Exit blocks
for.body.preheader:                               ; preds = %vector.body
  br label %for.body
*** IR Dump After Remove redundant instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Hoist/decompose integer division and remainder ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body.preheader, label %vector.body, !llvm.loop !6

for.body.preheader:                               ; preds = %vector.body
  br label %for.body

for.body:                                         ; preds = %for.body.preheader
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After LCSSA Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop-Closed SSA Form Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop Sink ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  %and = and i32 %add.lcssa, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Remove redundant instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Hoist/decompose integer division and remainder ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Simplify the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
Pass Arguments:  -tti -targetlibinfo -assumption-cache-tracker -targetpassconfig -machinemoduleinfo -tbaa -scoped-noalias -collector-metadata -profile-summary-info -machine-branch-prob -domtree -basicaa -aa -objc-arc-contract -pre-isel-intrinsic-lowering -atomic-expand -domtree -basicaa -verify -loops -loop-simplify -scalar-evolution -iv-users -loop-reduce -basicaa -aa -mergeicmps -expandmemcmp -gc-lowering -shadow-stack-gc-lowering -unreachableblockelim -domtree -loops -branch-prob -block-freq -consthoist -partially-inline-libcalls -post-inline-ee-instrument -scalarize-masked-mem-intrin -expand-reductions -domtree -interleaved-access -indirectbr-expand -domtree -loops -codegenprepare -rewrite-symbols -domtree -dwarfehprepare -safe-stack -stack-protector -verify -domtree -basicaa -aa -loops -branch-prob -amdgpu-isel -machineinstr-printer -machinedomtree -finalize-isel -machineinstr-printer -x86-domain-reassignment -machineinstr-printer -early-tailduplication -machineinstr-printer -opt-phis -machineinstr-printer -slotindexes -machineinstr-printer -stack-coloring -machineinstr-printer -localstackalloc -machineinstr-printer -dead-mi-elimination -machineinstr-printer -machinedomtree -machine-loops -machine-trace-metrics -early-ifcvt -machineinstr-printer -machine-combiner -machineinstr-printer -x86-cmov-conversion -machineinstr-printer -machinedomtree -machine-loops -early-machinelicm -machineinstr-printer -machine-block-freq -machine-cse -machineinstr-printer -machinepostdomtree -machine-sink -machineinstr-printer -peephole-opt -machineinstr-printer -dead-mi-elimination -machineinstr-printer -lrshrink -machineinstr-printer -x86-optimize-LEAs -machineinstr-printer -x86-cf-opt -machineinstr-printer -x86-avoid-SFB -machineinstr-printer -x86-slh -machineinstr-printer -machinedomtree -x86-flags-copy-lowering -machineinstr-printer -detect-dead-lanes -machineinstr-printer -processimpdefs -machineinstr-printer -unreachable-mbb-elimination -machineinstr-printer -livevars -machineinstr-printer -machinedomtree -machine-loops -phi-node-elimination -machineinstr-printer -twoaddressinstruction -machineinstr-printer -slotindexes -machineinstr-printer -liveintervals -machineinstr-printer -simple-register-coalescing -machineinstr-printer -rename-independent-subregs -machineinstr-printer -machine-scheduler -machineinstr-printer -machine-block-freq -livedebugvars -machineinstr-printer -livestacks -machineinstr-printer -virtregmap -machineinstr-printer -liveregmatrix -machineinstr-printer -edge-bundles -spill-code-placement -lazy-machine-block-freq -machine-opt-remark-emitter -greedy -machineinstr-printer -virtregrewriter -machineinstr-printer -stack-slot-coloring -machineinstr-printer -machine-cp -machineinstr-printer -machinelicm -machineinstr-printer -edge-bundles -x86-codegen -machineinstr-printer -postra-machine-sink -machineinstr-printer -machine-block-freq -machinepostdomtree -lazy-machine-block-freq -machine-opt-remark-emitter -shrink-wrap -machineinstr-printer -prologepilog -machineinstr-printer -branch-folder -machineinstr-printer -tailduplication -machineinstr-printer -machine-cp -machineinstr-printer -postrapseudos -machineinstr-printer -x86-pseudo -machineinstr-printer -machinedomtree -machine-loops -post-RA-sched -machineinstr-printer -gc-analysis -machineinstr-printer -machine-block-freq -machinepostdomtree -block-placement -machineinstr-printer -reaching-deps-analysis -x86-execution-domain-fix -machineinstr-printer -break-false-deps -machineinstr-printer -machinedomtree -machine-loops -x86-fixup-bw-insts -machineinstr-printer -x86-fixup-LEAs -machineinstr-printer -x86-evex-to-vex-compress -machineinstr-printer -funclet-layout -machineinstr-printer -stackmap-liveness -machineinstr-printer -livedebugvalues -machineinstr-printer -fentry-insert -machineinstr-printer -xray-instrumentation -machineinstr-printer -patchable-function -machineinstr-printer -cfi-instr-inserter -machineinstr-printer -lazy-machine-block-freq -machine-opt-remark-emitter
Target Transform Information
Target Library Information
Assumption Cache Tracker
Target Pass Configuration
Machine Module Information
Type-Based Alias Analysis
Scoped NoAlias Alias Analysis
Create Garbage Collector Module Metadata
Profile summary info
Machine Branch Probability Analysis
  ModulePass Manager
    FunctionPass Manager
      Dominator Tree Construction
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      ObjC ARC contraction
      Print Function IR
    Pre-ISel Intrinsic Lowering
    Print Module IR
    FunctionPass Manager
      Expand Atomic instructions
      Print Function IR
      Dominator Tree Construction
      Basic Alias Analysis (stateless AA impl)
      Module Verifier
      Print Function IR
      Natural Loop Information
      Canonicalize natural loops
      Print Function IR
      Scalar Evolution Analysis
      Loop Pass Manager
        Induction Variable Users
        Loop Strength Reduction
        Print Loop IR
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Merge contiguous icmps into a memcmp
      Print Function IR
      Expand memcmp() to load/stores
      Print Function IR
      Lower Garbage Collection Instructions
      Print Function IR
      Shadow Stack GC Lowering
      Print Function IR
      Remove unreachable blocks from the CFG
      Print Function IR
      Dominator Tree Construction
      Natural Loop Information
      Branch Probability Analysis
      Block Frequency Analysis
      Constant Hoisting
      Print Function IR
      Partially inline calls to library functions
      Print Function IR
      Instrument function entry/exit with calls to e.g. mcount() (post inlining)
      Print Function IR
      Scalarize Masked Memory Intrinsics
      Print Function IR
      Expand reduction intrinsics
      Print Function IR
      Dominator Tree Construction
      Interleaved Access Pass
      Print Function IR
      Expand indirectbr instructions
      Print Function IR
      Dominator Tree Construction
      Natural Loop Information
      CodeGen Prepare
      Print Function IR
    Rewrite Symbols
    Print Module IR
    FunctionPass Manager
      Dominator Tree Construction
      Exception handling preparation
      Print Function IR
      Safe Stack instrumentation pass
      Print Function IR
      Insert stack protectors
      Module Verifier
      Print Function IR
      Dominator Tree Construction
      Basic Alias Analysis (stateless AA impl)
      Function Alias Analysis Results
      Natural Loop Information
      Branch Probability Analysis
      X86 DAG->DAG Instruction Selection
      MachineFunction Printer
      MachineDominator Tree Construction
      Local Dynamic TLS Access Clean-up
      X86 PIC Global Base Reg Initialization
      Finalize ISel and expand pseudo-instructions
      MachineFunction Printer
      X86 Domain Reassignment Pass
      MachineFunction Printer
      Early Tail Duplication
      MachineFunction Printer
      Optimize machine instruction PHIs
      MachineFunction Printer
      Slot index numbering
      MachineFunction Printer
      Merge disjoint stack slots
      MachineFunction Printer
      Local Stack Slot Allocation
      MachineFunction Printer
      Remove dead machine instructions
      MachineFunction Printer
      MachineDominator Tree Construction
      Machine Natural Loop Construction
      Machine Trace Metrics
      Early If-Conversion
      MachineFunction Printer
      Machine InstCombiner
      MachineFunction Printer
      X86 cmov Conversion
      MachineFunction Printer
      MachineDominator Tree Construction
      Machine Natural Loop Construction
      Early Machine Loop Invariant Code Motion
      MachineFunction Printer
      Machine Block Frequency Analysis
      Machine Common Subexpression Elimination
      MachineFunction Printer
      MachinePostDominator Tree Construction
      Machine code sinking
      MachineFunction Printer
      Peephole Optimizations
      MachineFunction Printer
      Remove dead machine instructions
      MachineFunction Printer
      Live Range Shrink
      MachineFunction Printer
      X86 Fixup SetCC
      X86 LEA Optimize
      MachineFunction Printer
      X86 Optimize Call Frame
      MachineFunction Printer
      X86 Avoid Store Forwarding Blocks
      MachineFunction Printer
      X86 speculative load hardening
      MachineFunction Printer
      MachineDominator Tree Construction
      X86 EFLAGS copy lowering
      MachineFunction Printer
      X86 WinAlloca Expander
      Detect Dead Lanes
      MachineFunction Printer
      Process Implicit Definitions
      MachineFunction Printer
      Remove unreachable machine basic blocks
      MachineFunction Printer
      Live Variable Analysis
      MachineFunction Printer
      MachineDominator Tree Construction
      Machine Natural Loop Construction
      Eliminate PHI nodes for register allocation
      MachineFunction Printer
      Two-Address instruction pass
      MachineFunction Printer
      Slot index numbering
      MachineFunction Printer
      Live Interval Analysis
      MachineFunction Printer
      Simple Register Coalescing
      MachineFunction Printer
      Rename Disconnected Subregister Components
      MachineFunction Printer
      Machine Instruction Scheduler
      MachineFunction Printer
      Machine Block Frequency Analysis
      Debug Variable Analysis
      MachineFunction Printer
      Live Stack Slot Analysis
      MachineFunction Printer
      Virtual Register Map
      MachineFunction Printer
      Live Register Matrix
      MachineFunction Printer
      Bundle Machine CFG Edges
      Spill Code Placement Analysis
      Lazy Machine Block Frequency Analysis
      Machine Optimization Remark Emitter
      Greedy Register Allocator
      MachineFunction Printer
      Virtual Register Rewriter
      MachineFunction Printer
      Stack Slot Coloring
      MachineFunction Printer
      Machine Copy Propagation Pass
      MachineFunction Printer
      Machine Loop Invariant Code Motion
      MachineFunction Printer
      Bundle Machine CFG Edges
      X86 FP Stackifier
      MachineFunction Printer
      PostRA Machine Sink
      MachineFunction Printer
      Machine Block Frequency Analysis
      MachinePostDominator Tree Construction
      Lazy Machine Block Frequency Analysis
      Machine Optimization Remark Emitter
      Shrink Wrapping analysis
      MachineFunction Printer
      Prologue/Epilogue Insertion & Frame Finalization
      MachineFunction Printer
      Control Flow Optimizer
      MachineFunction Printer
      Tail Duplication
      MachineFunction Printer
      Machine Copy Propagation Pass
      MachineFunction Printer
      Post-RA pseudo instruction expansion pass
      MachineFunction Printer
      X86 pseudo instruction expansion pass
      MachineFunction Printer
      MachineDominator Tree Construction
      Machine Natural Loop Construction
      Post RA top-down list latency scheduler
      MachineFunction Printer
      Analyze Machine Code For Garbage Collection
      MachineFunction Printer
      Machine Block Frequency Analysis
      MachinePostDominator Tree Construction
      Branch Probability Basic Block Placement
      MachineFunction Printer
      ReachingDefAnalysis
      X86 Execution Dependency Fix
      MachineFunction Printer
      BreakFalseDeps
      MachineFunction Printer
      X86 Indirect Branch Tracking
      X86 vzeroupper inserter
      MachineDominator Tree Construction
      Machine Natural Loop Construction
      X86 Byte/Word Instruction Fixup
      MachineFunction Printer
      X86 Atom pad short functions
      X86 LEA Fixup
      MachineFunction Printer
      Compressing EVEX instrs to VEX encoding when possible
      MachineFunction Printer
      X86 Discriminate Memory Operands
      X86 Insert Cache Prefetches
      Contiguously Lay Out Funclets
      MachineFunction Printer
      StackMap Liveness Analysis
      MachineFunction Printer
      Live DEBUG_VALUE analysis
      MachineFunction Printer
      Insert fentry calls
      MachineFunction Printer
      Insert XRay ops
      MachineFunction Printer
      Implement the 'patchable-function' attribute
      MachineFunction Printer
      X86 Retpoline Thunks
      Check CFA info and insert CFI instructions if needed
      MachineFunction Printer
      Lazy Machine Block Frequency Analysis
      Machine Optimization Remark Emitter
      X86 Assembly Printer
      Free MachineFunction
*** IR Dump After ObjC ARC contraction ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After ObjC ARC contraction ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Pre-ISel Intrinsic Lowering ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.isvectorized", i32 1}
*** IR Dump After Expand Atomic instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Module Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %index = phi i64 [ 0, %entry ], [ %index.next, %vector.body ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %7 = or i64 %index, 1
  %8 = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %7
  %9 = bitcast i32* %8 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %9, align 4, !tbaa !2
  %10 = getelementptr inbounds i32, i32* %8, i64 8
  %11 = bitcast i32* %10 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %11, align 4, !tbaa !2
  %12 = getelementptr inbounds i32, i32* %8, i64 16
  %13 = bitcast i32* %12 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %13, align 4, !tbaa !2
  %14 = getelementptr inbounds i32, i32* %8, i64 24
  %15 = bitcast i32* %14 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %15, align 4, !tbaa !2
  %index.next = add i64 %index, 32
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %16 = icmp eq i64 %index.next, 134080
  br i1 %16, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %17 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %17
}
*** IR Dump After Loop Strength Reduction ***
; Preheader:
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

; Loop:
vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

; Exit blocks
for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
*** IR Dump After Merge contiguous icmps into a memcmp ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Expand memcmp() to load/stores ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Lower Garbage Collection Instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Shadow Stack GC Lowering ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Remove unreachable blocks from the CFG ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Constant Hoisting ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Partially inline calls to library functions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Instrument function entry/exit with calls to e.g. mcount() (post inlining) ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Scalarize Masked Memory Intrinsics ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Expand reduction intrinsics ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Interleaved Access Pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Expand indirectbr instructions ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %lsr.iv29 = inttoptr i64 %lsr.iv to <8 x i32>*
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After CodeGen Prepare ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Expand Atomic instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Module Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Canonicalize natural loops ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Loop Strength Reduction ***
; Preheader:
entry:
  br label %for.body

; Loop:
for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

; Exit blocks
for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0
*** IR Dump After Merge contiguous icmps into a memcmp ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Expand memcmp() to load/stores ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Lower Garbage Collection Instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Shadow Stack GC Lowering ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Remove unreachable blocks from the CFG ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Constant Hoisting ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Partially inline calls to library functions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Instrument function entry/exit with calls to e.g. mcount() (post inlining) ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Scalarize Masked Memory Intrinsics ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Expand reduction intrinsics ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Interleaved Access Pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Expand indirectbr instructions ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After CodeGen Prepare ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Rewrite Symbols ***
; ModuleID = 'dep.c'
source_filename = "dep.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global <{ i32, [134097 x i32] }> <{ i32 1, [134097 x i32] zeroinitializer }>, align 16

; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

attributes #0 = { nofree noinline norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 10.0.0 (http://github.com/llvm-mirror/clang.git 3441aaff8506ac0252f9bba9d1ce117cf35906ce) (http://github.com/llvm-mirror/llvm.git 2e6b938e4e31a2fdd8a5b3ec969bee9dcf9806a7)"}
!2 = !{!3, !3, i64 0}
!3 = !{!"int", !4, i64 0}
!4 = !{!"omnipotent char", !5, i64 0}
!5 = !{!"Simple C/C++ TBAA"}
!6 = distinct !{!6, !7}
!7 = !{!"llvm.loop.isvectorized", i32 1}
*** IR Dump After Exception handling preparation ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Safe Stack instrumentation pass ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
*** IR Dump After Module Verifier ***
; Function Attrs: nofree noinline norecurse nounwind uwtable
define dso_local i32 @workload(i32 %init) local_unnamed_addr #0 {
entry:
  %.pre = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0), align 16, !tbaa !2
  %0 = mul i32 %init, 134080
  %ind.end = add i32 %.pre, %0
  %.splatinsert = insertelement <8 x i32> undef, i32 %.pre, i32 0
  %.splat = shufflevector <8 x i32> %.splatinsert, <8 x i32> undef, <8 x i32> zeroinitializer
  %.splatinsert10 = insertelement <8 x i32> undef, i32 %init, i32 0
  %.splat11 = shufflevector <8 x i32> %.splatinsert10, <8 x i32> undef, <8 x i32> zeroinitializer
  %1 = mul <8 x i32> %.splat11, <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %induction = add <8 x i32> %.splat, %1
  %2 = shl i32 %init, 3
  %.splatinsert12 = insertelement <8 x i32> undef, i32 %2, i32 0
  %.splat13 = shufflevector <8 x i32> %.splatinsert12, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert21 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat22 = shufflevector <8 x i32> %broadcast.splatinsert21, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert23 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat24 = shufflevector <8 x i32> %broadcast.splatinsert23, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert25 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat26 = shufflevector <8 x i32> %broadcast.splatinsert25, <8 x i32> undef, <8 x i32> zeroinitializer
  %broadcast.splatinsert27 = insertelement <8 x i32> undef, i32 %init, i32 0
  %broadcast.splat28 = shufflevector <8 x i32> %broadcast.splatinsert27, <8 x i32> undef, <8 x i32> zeroinitializer
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %entry
  %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ -536320, %entry ]
  %vec.ind = phi <8 x i32> [ %induction, %entry ], [ %vec.ind.next, %vector.body ]
  %step.add = add <8 x i32> %vec.ind, %.splat13
  %step.add14 = add <8 x i32> %step.add, %.splat13
  %step.add15 = add <8 x i32> %step.add14, %.splat13
  %3 = add nsw <8 x i32> %vec.ind, %broadcast.splat22
  %4 = add nsw <8 x i32> %step.add, %broadcast.splat24
  %5 = add nsw <8 x i32> %step.add14, %broadcast.splat26
  %6 = add nsw <8 x i32> %step.add15, %broadcast.splat28
  %uglygep = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep30 = bitcast i8* %uglygep to <8 x i32>*
  %scevgep = getelementptr <8 x i32>, <8 x i32>* %uglygep30, i64 16760
  %scevgep31 = bitcast <8 x i32>* %scevgep to i8*
  %uglygep32 = getelementptr i8, i8* %scevgep31, i64 4
  %uglygep3233 = bitcast i8* %uglygep32 to <8 x i32>*
  store <8 x i32> %3, <8 x i32>* %uglygep3233, align 4, !tbaa !2
  %uglygep46 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4647 = bitcast i8* %uglygep46 to <8 x i32>*
  %scevgep48 = getelementptr <8 x i32>, <8 x i32>* %uglygep4647, i64 16761
  %scevgep4849 = bitcast <8 x i32>* %scevgep48 to i8*
  %uglygep50 = getelementptr i8, i8* %scevgep4849, i64 4
  %uglygep5051 = bitcast i8* %uglygep50 to <8 x i32>*
  store <8 x i32> %4, <8 x i32>* %uglygep5051, align 4, !tbaa !2
  %uglygep40 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep4041 = bitcast i8* %uglygep40 to <8 x i32>*
  %scevgep42 = getelementptr <8 x i32>, <8 x i32>* %uglygep4041, i64 16762
  %scevgep4243 = bitcast <8 x i32>* %scevgep42 to i8*
  %uglygep44 = getelementptr i8, i8* %scevgep4243, i64 4
  %uglygep4445 = bitcast i8* %uglygep44 to <8 x i32>*
  store <8 x i32> %5, <8 x i32>* %uglygep4445, align 4, !tbaa !2
  %uglygep34 = getelementptr i8, i8* bitcast (<{ i32, [134097 x i32] }>* @arr to i8*), i64 %lsr.iv
  %uglygep3435 = bitcast i8* %uglygep34 to <8 x i32>*
  %scevgep36 = getelementptr <8 x i32>, <8 x i32>* %uglygep3435, i64 16763
  %scevgep3637 = bitcast <8 x i32>* %scevgep36 to i8*
  %uglygep38 = getelementptr i8, i8* %scevgep3637, i64 4
  %uglygep3839 = bitcast i8* %uglygep38 to <8 x i32>*
  store <8 x i32> %6, <8 x i32>* %uglygep3839, align 4, !tbaa !2
  %vec.ind.next = add <8 x i32> %step.add15, %.splat13
  %lsr.iv.next = add nsw i64 %lsr.iv, 128
  %7 = icmp eq i64 %lsr.iv.next, 0
  br i1 %7, label %for.body, label %vector.body, !llvm.loop !6

for.body:                                         ; preds = %vector.body
  %add = add nsw i32 %ind.end, %init
  store i32 %add, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080), align 4, !tbaa !2
  %add.1 = add nsw i32 %add, %init
  store i32 %add.1, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081), align 4, !tbaa !2
  %add.2 = add nsw i32 %add.1, %init
  store i32 %add.2, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082), align 4, !tbaa !2
  %add.3 = add nsw i32 %add.2, %init
  store i32 %add.3, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083), align 4, !tbaa !2
  %add.4 = add nsw i32 %add.3, %init
  store i32 %add.4, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084), align 4, !tbaa !2
  %add.5 = add nsw i32 %add.4, %init
  store i32 %add.5, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085), align 4, !tbaa !2
  %add.6 = add nsw i32 %add.5, %init
  store i32 %add.6, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086), align 4, !tbaa !2
  %add.7 = add nsw i32 %add.6, %init
  store i32 %add.7, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087), align 4, !tbaa !2
  %add.8 = add nsw i32 %add.7, %init
  store i32 %add.8, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088), align 4, !tbaa !2
  %add.9 = add nsw i32 %add.8, %init
  store i32 %add.9, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089), align 4, !tbaa !2
  %add.10 = add nsw i32 %add.9, %init
  store i32 %add.10, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090), align 4, !tbaa !2
  %add.11 = add nsw i32 %add.10, %init
  store i32 %add.11, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091), align 4, !tbaa !2
  %add.12 = add nsw i32 %add.11, %init
  store i32 %add.12, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092), align 4, !tbaa !2
  %add.13 = add nsw i32 %add.12, %init
  store i32 %add.13, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093), align 4, !tbaa !2
  %add.14 = add nsw i32 %add.13, %init
  store i32 %add.14, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094), align 4, !tbaa !2
  %add.15 = add nsw i32 %add.14, %init
  store i32 %add.15, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095), align 4, !tbaa !2
  %add.16 = add nsw i32 %add.15, %init
  store i32 %add.16, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096), align 4, !tbaa !2
  %add.17 = add nsw i32 %add.16, %init
  store i32 %add.17, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0), align 8, !tbaa !2
  %8 = load i32, i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6), align 4, !tbaa !2
  ret i32 %8
}
# *** IR Dump After X86 DAG->DAG Instruction Selection ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Finalize ISel and expand pseudo-instructions ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 Domain Reassignment Pass ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Early Tail Duplication ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Optimize machine instruction PHIs ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Slot index numbering ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  %11:gr32 = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
64B	  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
80B	  %15:vr128 = COPY %13:gr32
96B	  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
112B	  %17:vr128 = COPY %11:gr32
128B	  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
144B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
160B	  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
176B	  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
192B	  %20:vr128 = COPY %19:gr32
208B	  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
224B	  %4:vr256 = COPY %3:vr256
240B	  %5:vr256 = COPY %3:vr256
256B	  %12:gr64 = MOV64ri32 -536320
272B	  %6:vr256 = COPY %3:vr256

288B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

304B	  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
320B	  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
336B	  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
352B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
368B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
384B	  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
400B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
416B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
432B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
448B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
464B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
480B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
496B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
512B	  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
528B	  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
544B	  JCC_1 %bb.1, 5, implicit $eflags
560B	  JMP_1 %bb.2

576B	bb.2.for.body:
	; predecessors: %bb.1

592B	  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
608B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
624B	  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
640B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
656B	  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
672B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
688B	  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
704B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
720B	  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
752B	  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
768B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
784B	  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
800B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
816B	  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
848B	  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
864B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
880B	  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
896B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
912B	  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
944B	  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
960B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
976B	  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
992B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1008B	  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1040B	  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1056B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1072B	  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1088B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1104B	  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1136B	  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1152B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1168B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1184B	  $eax = COPY %46:gr32
1200B	  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Merge disjoint stack slots ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Local Stack Slot Allocation ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Remove dead machine instructions ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Early If-Conversion ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Machine InstCombiner ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 cmov Conversion ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Early Machine Loop Invariant Code Motion ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %4:vr256 = COPY %3:vr256
  %5:vr256 = COPY %3:vr256
  %12:gr64 = MOV64ri32 -536320
  %6:vr256 = COPY %3:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %4:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %5:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %6:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Machine Common Subexpression Elimination ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Machine code sinking ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Peephole Optimizations ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Remove dead machine instructions ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Live Range Shrink ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 LEA Optimize ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 Optimize Call Frame ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 Avoid Store Forwarding Blocks ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 speculative load hardening ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 EFLAGS copy lowering ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Detect Dead Lanes ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Process Implicit Definitions ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Remove unreachable machine basic blocks ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY %46:gr32
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Live Variable Analysis ***:
# Machine code for function workload: IsSSA, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY killed $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY killed %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY killed %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %7:gr64 = PHI %12:gr64, %bb.0, %10:gr64, %bb.1
  %8:vr256 = PHI %1:vr256, %bb.0, %9:vr256, %bb.1
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr killed %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr killed %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr killed %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr killed %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 killed %7:gr64(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr killed %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr killed %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr killed %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr killed %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr killed %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr killed %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr killed %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr killed %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr killed %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr killed %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr killed %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr killed %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr killed %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr killed %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr killed %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr killed %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr killed %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr killed %44:gr32(tied-def 0), killed %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY killed %46:gr32
  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Eliminate PHI nodes for register allocation ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY killed $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = ADD32rr %13:gr32(tied-def 0), killed %14:gr32, implicit-def dead $eflags
  %15:vr128 = COPY killed %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  %19:gr32 = SHL32ri %11:gr32(tied-def 0), 3, implicit-def dead $eflags
  %20:vr128 = COPY killed %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320
  %47:gr64 = COPY killed %12:gr64
  %48:vr256 = COPY killed %1:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %8:vr256 = COPY killed %48:vr256
  %7:gr64 = COPY killed %47:gr64
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr killed %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr killed %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr killed %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr killed %23:vr256, %2:vr256
  %10:gr64 = SUB64ri8 killed %7:gr64(tied-def 0), -128, implicit-def $eflags
  %47:gr64 = COPY killed %10:gr64
  %48:vr256 = COPY killed %9:vr256
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = nsw ADD32rr killed %0:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = nsw ADD32rr killed %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = nsw ADD32rr killed %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = nsw ADD32rr killed %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = nsw ADD32rr killed %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = nsw ADD32rr killed %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = nsw ADD32rr killed %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = nsw ADD32rr killed %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = nsw ADD32rr killed %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = nsw ADD32rr killed %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = nsw ADD32rr killed %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = nsw ADD32rr killed %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = nsw ADD32rr killed %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = nsw ADD32rr killed %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = nsw ADD32rr killed %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = nsw ADD32rr killed %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = nsw ADD32rr killed %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = nsw ADD32rr killed %44:gr32(tied-def 0), killed %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY killed %46:gr32
  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Two-Address instruction pass ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  %11:gr32 = COPY killed $edi
  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
  %0:gr32 = COPY killed %14:gr32
  %0:gr32 = ADD32rr %0:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
  %15:vr128 = COPY killed %13:gr32
  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
  %17:vr128 = COPY %11:gr32
  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
  undef %49.sub_32bit:gr64_nosp = COPY %11:gr32
  %19:gr32 = LEA64_32r $noreg, 8, killed %49:gr64_nosp, 0, $noreg
  %20:vr128 = COPY killed %19:gr32
  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
  %12:gr64 = MOV64ri32 -536320
  %47:gr64 = COPY killed %12:gr64
  %48:vr256 = COPY killed %1:vr256

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

  %8:vr256 = COPY killed %48:vr256
  %7:gr64 = COPY killed %47:gr64
  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
  %24:vr256 = nsw VPADDDYrr killed %8:vr256, %3:vr256
  %25:vr256 = nsw VPADDDYrr killed %21:vr256, %3:vr256
  %26:vr256 = nsw VPADDDYrr killed %22:vr256, %3:vr256
  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  %9:vr256 = VPADDDYrr killed %23:vr256, %2:vr256
  %10:gr64 = COPY killed %7:gr64
  %10:gr64 = SUB64ri8 %10:gr64(tied-def 0), -128, implicit-def $eflags
  %47:gr64 = COPY killed %10:gr64
  %48:vr256 = COPY killed %9:vr256
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1

  %28:gr32 = COPY killed %0:gr32
  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  %29:gr32 = COPY killed %28:gr32
  %29:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  %30:gr32 = COPY killed %29:gr32
  %30:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  %31:gr32 = COPY killed %30:gr32
  %31:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  %32:gr32 = COPY killed %31:gr32
  %32:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  %33:gr32 = COPY killed %32:gr32
  %33:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  %34:gr32 = COPY killed %33:gr32
  %34:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  %35:gr32 = COPY killed %34:gr32
  %35:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  %36:gr32 = COPY killed %35:gr32
  %36:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  %37:gr32 = COPY killed %36:gr32
  %37:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  %38:gr32 = COPY killed %37:gr32
  %38:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  %39:gr32 = COPY killed %38:gr32
  %39:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  %40:gr32 = COPY killed %39:gr32
  %40:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  %41:gr32 = COPY killed %40:gr32
  %41:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  %42:gr32 = COPY killed %41:gr32
  %42:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  %43:gr32 = COPY killed %42:gr32
  %43:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  %44:gr32 = COPY killed %43:gr32
  %44:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  %45:gr32 = COPY killed %44:gr32
  %45:gr32 = nsw ADD32rr %45:gr32(tied-def 0), killed %11:gr32, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  $eax = COPY killed %46:gr32
  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Slot index numbering ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  %11:gr32 = COPY killed $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
64B	  %0:gr32 = COPY killed %14:gr32
80B	  %0:gr32 = ADD32rr %0:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY killed %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr killed %15:vr128
128B	  %17:vr128 = COPY %11:gr32
144B	  %3:vr256 = VPBROADCASTDYrr killed %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %1:vr256 = VPADDDYrr killed %16:vr256, killed %18:vr256
192B	  undef %49.sub_32bit:gr64_nosp = COPY %11:gr32
208B	  %19:gr32 = LEA64_32r $noreg, 8, killed %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY killed %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr killed %20:vr128
256B	  %12:gr64 = MOV64ri32 -536320
272B	  %47:gr64 = COPY killed %12:gr64
288B	  %48:vr256 = COPY killed %1:vr256

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

320B	  %8:vr256 = COPY killed %48:vr256
336B	  %7:gr64 = COPY killed %47:gr64
352B	  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr killed %8:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr killed %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr killed %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, killed %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, killed %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, killed %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, killed %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %9:vr256 = VPADDDYrr killed %23:vr256, %2:vr256
544B	  %10:gr64 = COPY killed %7:gr64
560B	  %10:gr64 = SUB64ri8 %10:gr64(tied-def 0), -128, implicit-def $eflags
576B	  %47:gr64 = COPY killed %10:gr64
592B	  %48:vr256 = COPY killed %9:vr256
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

656B	  %28:gr32 = COPY killed %0:gr32
672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
704B	  %29:gr32 = COPY killed %28:gr32
720B	  %29:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
752B	  %30:gr32 = COPY killed %29:gr32
768B	  %30:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
800B	  %31:gr32 = COPY killed %30:gr32
816B	  %31:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
848B	  %32:gr32 = COPY killed %31:gr32
864B	  %32:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
896B	  %33:gr32 = COPY killed %32:gr32
912B	  %33:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
944B	  %34:gr32 = COPY killed %33:gr32
960B	  %34:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
992B	  %35:gr32 = COPY killed %34:gr32
1008B	  %35:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1040B	  %36:gr32 = COPY killed %35:gr32
1056B	  %36:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1088B	  %37:gr32 = COPY killed %36:gr32
1104B	  %37:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1136B	  %38:gr32 = COPY killed %37:gr32
1152B	  %38:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1184B	  %39:gr32 = COPY killed %38:gr32
1200B	  %39:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1232B	  %40:gr32 = COPY killed %39:gr32
1248B	  %40:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1280B	  %41:gr32 = COPY killed %40:gr32
1296B	  %41:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1328B	  %42:gr32 = COPY killed %41:gr32
1344B	  %42:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1376B	  %43:gr32 = COPY killed %42:gr32
1392B	  %43:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1424B	  %44:gr32 = COPY killed %43:gr32
1440B	  %44:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1472B	  %45:gr32 = COPY killed %44:gr32
1488B	  %45:gr32 = nsw ADD32rr %45:gr32(tied-def 0), killed %11:gr32, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY killed %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Live Interval Analysis ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  %11:gr32 = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %14:gr32 = IMUL32rri %11:gr32, 134080, implicit-def dead $eflags
64B	  %0:gr32 = COPY %14:gr32
80B	  %0:gr32 = ADD32rr %0:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %11:gr32
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %1:vr256 = VPADDDYrr %16:vr256, %18:vr256
192B	  undef %49.sub_32bit:gr64_nosp = COPY %11:gr32
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %12:gr64 = MOV64ri32 -536320
272B	  %47:gr64 = COPY %12:gr64
288B	  %48:vr256 = COPY %1:vr256

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

320B	  %8:vr256 = COPY %48:vr256
336B	  %7:gr64 = COPY %47:gr64
352B	  %21:vr256 = VPADDDYrr %8:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %8:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %7:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %9:vr256 = VPADDDYrr %23:vr256, %2:vr256
544B	  %10:gr64 = COPY %7:gr64
560B	  %10:gr64 = SUB64ri8 %10:gr64(tied-def 0), -128, implicit-def $eflags
576B	  %47:gr64 = COPY %10:gr64
592B	  %48:vr256 = COPY %9:vr256
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

656B	  %28:gr32 = COPY %0:gr32
672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
704B	  %29:gr32 = COPY %28:gr32
720B	  %29:gr32 = nsw ADD32rr %29:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %29:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
752B	  %30:gr32 = COPY %29:gr32
768B	  %30:gr32 = nsw ADD32rr %30:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %30:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
800B	  %31:gr32 = COPY %30:gr32
816B	  %31:gr32 = nsw ADD32rr %31:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %31:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
848B	  %32:gr32 = COPY %31:gr32
864B	  %32:gr32 = nsw ADD32rr %32:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %32:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
896B	  %33:gr32 = COPY %32:gr32
912B	  %33:gr32 = nsw ADD32rr %33:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %33:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
944B	  %34:gr32 = COPY %33:gr32
960B	  %34:gr32 = nsw ADD32rr %34:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %34:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
992B	  %35:gr32 = COPY %34:gr32
1008B	  %35:gr32 = nsw ADD32rr %35:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %35:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1040B	  %36:gr32 = COPY %35:gr32
1056B	  %36:gr32 = nsw ADD32rr %36:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %36:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1088B	  %37:gr32 = COPY %36:gr32
1104B	  %37:gr32 = nsw ADD32rr %37:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %37:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1136B	  %38:gr32 = COPY %37:gr32
1152B	  %38:gr32 = nsw ADD32rr %38:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %38:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1184B	  %39:gr32 = COPY %38:gr32
1200B	  %39:gr32 = nsw ADD32rr %39:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %39:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1232B	  %40:gr32 = COPY %39:gr32
1248B	  %40:gr32 = nsw ADD32rr %40:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %40:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1280B	  %41:gr32 = COPY %40:gr32
1296B	  %41:gr32 = nsw ADD32rr %41:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %41:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1328B	  %42:gr32 = COPY %41:gr32
1344B	  %42:gr32 = nsw ADD32rr %42:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %42:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1376B	  %43:gr32 = COPY %42:gr32
1392B	  %43:gr32 = nsw ADD32rr %43:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %43:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1424B	  %44:gr32 = COPY %43:gr32
1440B	  %44:gr32 = nsw ADD32rr %44:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %44:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1472B	  %45:gr32 = COPY %44:gr32
1488B	  %45:gr32 = nsw ADD32rr %45:gr32(tied-def 0), %11:gr32, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %45:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Simple Register Coalescing ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Rename Disconnected Subregister Components ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Machine Instruction Scheduler ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Debug Variable Analysis ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Live Stack Slot Analysis ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Virtual Register Map ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Live Register Matrix ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, killed $eax

# End machine code for function workload.

# *** IR Dump After Greedy Register Allocator ***:
# Machine code for function workload: NoPHIs, TracksLiveness
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi in %11

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  undef %49.sub_32bit:gr64_nosp = COPY $edi
32B	  %13:gr32 = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  %28:gr32 = IMUL32rri %49.sub_32bit:gr64_nosp, 134080, implicit-def dead $eflags
80B	  %28:gr32 = ADD32rr %28:gr32(tied-def 0), %13:gr32, implicit-def dead $eflags
96B	  %15:vr128 = COPY %13:gr32
112B	  %16:vr256 = VPBROADCASTDYrr %15:vr128
128B	  %17:vr128 = COPY %49.sub_32bit:gr64_nosp
144B	  %3:vr256 = VPBROADCASTDYrr %17:vr128
160B	  %18:vr256 = VPMULLDYrm %3:vr256, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  %48:vr256 = VPADDDYrr %16:vr256, %18:vr256
208B	  %19:gr32 = LEA64_32r $noreg, 8, %49:gr64_nosp, 0, $noreg
224B	  %20:vr128 = COPY %19:gr32
240B	  %2:vr256 = VPBROADCASTDYrr %20:vr128
256B	  %47:gr64 = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)

352B	  %21:vr256 = VPADDDYrr %48:vr256, %2:vr256
368B	  %22:vr256 = VPADDDYrr %21:vr256, %2:vr256
384B	  %23:vr256 = VPADDDYrr %22:vr256, %2:vr256
400B	  %24:vr256 = nsw VPADDDYrr %48:vr256, %3:vr256
416B	  %25:vr256 = nsw VPADDDYrr %21:vr256, %3:vr256
432B	  %26:vr256 = nsw VPADDDYrr %22:vr256, %3:vr256
448B	  %27:vr256 = nsw VPADDDYrr %23:vr256, %3:vr256
464B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536324, $noreg, %24:vr256 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536356, $noreg, %25:vr256 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536388, $noreg, %26:vr256 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr %47:gr64, 1, $noreg, @arr + 536420, $noreg, %27:vr256 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  %48:vr256 = VPADDDYrr %23:vr256, %2:vr256
560B	  %47:gr64 = SUB64ri8 %47:gr64(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1

672B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  %28:gr32 = nsw ADD32rr %28:gr32(tied-def 0), %49.sub_32bit:gr64_nosp, implicit-def dead $eflags
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, %28:gr32 :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  %46:gr32 = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1536B	  $eax = COPY %46:gr32
1552B	  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Virtual Register Rewriter ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  renamable $edi = KILL $edi, implicit-def $rdi
32B	  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
80B	  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
96B	  renamable $xmm0 = COPY killed renamable $ecx
112B	  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
128B	  renamable $xmm0 = COPY renamable $edi
144B	  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
160B	  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
208B	  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
224B	  renamable $xmm1 = COPY killed renamable $ecx
240B	  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
256B	  renamable $rcx = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
	  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
352B	  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
368B	  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
384B	  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
400B	  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
416B	  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
432B	  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
448B	  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
464B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
560B	  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1
	  liveins: $eax, $rdi
672B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1552B	  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Stack Slot Coloring ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

0B	bb.0.entry:
	  successors: %bb.1(0x80000000); %bb.1(100.00%)
	  liveins: $edi
16B	  renamable $edi = KILL $edi, implicit-def $rdi
32B	  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
48B	  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
80B	  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
96B	  renamable $xmm0 = COPY killed renamable $ecx
112B	  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
128B	  renamable $xmm0 = COPY renamable $edi
144B	  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
160B	  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
176B	  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
208B	  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
224B	  renamable $xmm1 = COPY killed renamable $ecx
240B	  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
256B	  renamable $rcx = MOV64ri32 -536320

304B	bb.1.vector.body:
	; predecessors: %bb.0, %bb.1
	  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
	  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
352B	  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
368B	  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
384B	  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
400B	  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
416B	  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
432B	  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
448B	  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
464B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
480B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
496B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
512B	  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
528B	  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
560B	  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
608B	  JCC_1 %bb.1, 5, implicit killed $eflags
624B	  JMP_1 %bb.2

640B	bb.2.for.body:
	; predecessors: %bb.1
	  liveins: $eax, $rdi
672B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
688B	  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
720B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
736B	  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
768B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
784B	  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
816B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
832B	  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
864B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
880B	  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
912B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
928B	  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
960B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
976B	  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
1008B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1024B	  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
1056B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1072B	  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
1104B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1120B	  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
1152B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1168B	  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
1200B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1216B	  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
1248B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1264B	  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
1296B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1312B	  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
1344B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1360B	  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
1392B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1408B	  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
1440B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
1456B	  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
1488B	  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
1504B	  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
1520B	  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
1552B	  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Machine Copy Propagation Pass ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Machine Loop Invariant Code Motion ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 FP Stackifier ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After PostRA Machine Sink ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Shrink Wrapping analysis ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Prologue/Epilogue Insertion & Frame Finalization ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags
  JMP_1 %bb.2

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Control Flow Optimizer ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Tail Duplication ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Machine Copy Propagation Pass ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  renamable $xmm0 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $xmm0 = COPY renamable $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  renamable $xmm1 = COPY killed renamable $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After Post-RA pseudo instruction expansion pass ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RET 0, $eax

# End machine code for function workload.

# *** IR Dump After X86 pseudo instruction expansion pass ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Post RA top-down list latency scheduler ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Analyze Machine Code For Garbage Collection ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Branch Probability Basic Block Placement ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVUPSYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After X86 Execution Dependency Fix ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After BreakFalseDeps ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After X86 Byte/Word Instruction Fixup ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After X86 LEA Fixup ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Compressing EVEX instrs to VEX encoding when possible ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Contiguously Lay Out Funclets ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After StackMap Liveness Analysis ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Live DEBUG_VALUE analysis ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Insert fentry calls ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Insert XRay ops ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Implement the 'patchable-function' attribute ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

# *** IR Dump After Check CFA info and insert CFI instructions if needed ***:
# Machine code for function workload: NoPHIs, TracksLiveness, NoVRegs
Constant Pool:
  cp#0: <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, align=32
Function Live Ins: $edi

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $edi
  renamable $edi = KILL $edi, implicit-def $rdi
  renamable $ecx = MOV32rm $rip, 1, $noreg, @arr, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 0)`, align 16, !tbaa !2)
  renamable $eax = IMUL32rri renamable $edi, 134080, implicit-def dead $eflags
  renamable $eax = ADD32rr killed renamable $eax(tied-def 0), renamable $ecx, implicit-def dead $eflags
  $xmm0 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm0
  $xmm0 = VMOVDI2PDIrr $edi
  renamable $ymm0 = VPBROADCASTDYrr killed renamable $xmm0
  renamable $ymm2 = VPMULLDYrm renamable $ymm0, $rip, 1, $noreg, %const.0, $noreg :: (load 32 from constant-pool)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm1, killed renamable $ymm2
  renamable $ecx = LEA64_32r $noreg, 8, renamable $rdi, 0, $noreg
  $xmm1 = VMOVDI2PDIrr killed $ecx
  renamable $ymm1 = VPBROADCASTDYrr killed renamable $xmm1
  renamable $rcx = MOV64ri32 -536320

bb.1.vector.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $eax, $rcx, $rdi, $ymm0, $ymm1, $ymm2
  renamable $ymm3 = VPADDDYrr renamable $ymm2, renamable $ymm1
  renamable $ymm4 = VPADDDYrr renamable $ymm3, renamable $ymm1
  renamable $ymm5 = VPADDDYrr renamable $ymm4, renamable $ymm1
  renamable $ymm2 = nsw VPADDDYrr killed renamable $ymm2, renamable $ymm0
  renamable $ymm3 = nsw VPADDDYrr killed renamable $ymm3, renamable $ymm0
  renamable $ymm4 = nsw VPADDDYrr killed renamable $ymm4, renamable $ymm0
  renamable $ymm6 = nsw VPADDDYrr renamable $ymm5, renamable $ymm0
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536324, $noreg, killed renamable $ymm2 :: (store 32 into %ir.uglygep3233, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536356, $noreg, killed renamable $ymm3 :: (store 32 into %ir.uglygep5051, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536388, $noreg, killed renamable $ymm4 :: (store 32 into %ir.uglygep4445, align 4, !tbaa !2)
  VMOVDQUYmr renamable $rcx, 1, $noreg, @arr + 536420, $noreg, killed renamable $ymm6 :: (store 32 into %ir.uglygep3839, align 4, !tbaa !2)
  renamable $ymm2 = VPADDDYrr killed renamable $ymm5, renamable $ymm1
  renamable $rcx = SUB64ri8 killed renamable $rcx(tied-def 0), -128, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit killed $eflags

bb.2.for.body:
; predecessors: %bb.1
  liveins: $eax, $rdi
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536324, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134080)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536328, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134081)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536332, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134082)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536336, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134083)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536340, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134084)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536344, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134085)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536348, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134086)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536352, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134087)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536356, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134088)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536360, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134089)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536364, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134090)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536368, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134091)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536372, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134092)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536376, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134093)`, align 8, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536380, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134094)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536384, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134095)`, align 16, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags
  MOV32mr $rip, 1, $noreg, @arr + 536388, $noreg, renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 134096)`, !tbaa !2)
  renamable $eax = nsw ADD32rr killed renamable $eax(tied-def 0), renamable $edi, implicit-def dead $eflags, implicit killed $rdi
  MOV32mr $rip, 1, $noreg, @arr + 536392, $noreg, killed renamable $eax :: (store 4 into `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 1, i32 0)`, align 8, !tbaa !2)
  renamable $eax = MOV32rm $rip, 1, $noreg, @arr + 28, $noreg :: (dereferenceable load 4 from `i32* getelementptr inbounds (<{ i32, [134097 x i32] }>, <{ i32, [134097 x i32] }>* @arr, i64 0, i32 1, i64 6)`, !tbaa !2)
  VZEROUPPER implicit-def $ymm0, implicit-def $ymm1, implicit-def $ymm2, implicit-def $ymm3, implicit-def $ymm4, implicit-def $ymm5, implicit-def $ymm6, implicit-def $ymm7, implicit-def $ymm8, implicit-def $ymm9, implicit-def $ymm10, implicit-def $ymm11, implicit-def $ymm12, implicit-def $ymm13, implicit-def $ymm14, implicit-def $ymm15
  RETQ $eax

# End machine code for function workload.

*** IR Dump After Exception handling preparation ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Safe Stack instrumentation pass ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
*** IR Dump After Module Verifier ***
; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @main() local_unnamed_addr #1 {
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %and = and i32 %add, 4097
  %idxprom = zext i32 %and to i64
  %arrayidx = getelementptr inbounds [134098 x i32], [134098 x i32]* bitcast (<{ i32, [134097 x i32] }>* @arr to [134098 x i32]*), i64 0, i64 %idxprom
  %0 = load i32, i32* %arrayidx, align 4, !tbaa !2
  ret i32 %0

for.body:                                         ; preds = %for.body, %entry
  %i.07 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
  %index.06 = phi i32 [ 0, %entry ], [ %add, %for.body ]
  %call = tail call i32 @workload(i32 %i.07)
  %add = add nsw i32 %call, %index.06
  %inc = add nuw nsw i32 %i.07, 1
  %exitcond = icmp eq i32 %inc, 100000
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
# *** IR Dump After X86 DAG->DAG Instruction Selection ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Finalize ISel and expand pseudo-instructions ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 Domain Reassignment Pass ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Early Tail Duplication ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Optimize machine instruction PHIs ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Slot index numbering ***:
# Machine code for function main: IsSSA, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %4:gr32 = MOV32r0 implicit-def dead $eflags
32B	  JMP_1 %bb.2

48B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

64B	  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
80B	  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
96B	  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
112B	  $eax = COPY %9:gr32
128B	  RET 0, $eax

144B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

160B	  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
176B	  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
192B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
208B	  $edi = COPY %0:gr32
224B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
240B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  %5:gr32 = COPY $eax
272B	  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
288B	  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
304B	  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
320B	  JCC_1 %bb.1, 4, implicit $eflags
336B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Merge disjoint stack slots ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Local Stack Slot Allocation ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Remove dead machine instructions ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Early If-Conversion ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Machine InstCombiner ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 cmov Conversion ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Early Machine Loop Invariant Code Motion ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Machine Common Subexpression Elimination ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Machine code sinking ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %5:gr32(tied-def 0), %1:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  %6:gr32 = SUB32ri %3:gr32(tied-def 0), 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Peephole Optimizations ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Remove dead machine instructions ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Live Range Shrink ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 LEA Optimize ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 Optimize Call Frame ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 Avoid Store Forwarding Blocks ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 speculative load hardening ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 EFLAGS copy lowering ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Detect Dead Lanes ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Process Implicit Definitions ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Remove unreachable machine basic blocks ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY %9:gr32
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY $eax
  %2:gr32 = nsw ADD32rr %1:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Live Variable Analysis ***:
# Machine code for function main: IsSSA, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri killed %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY killed %9:gr32
  RET 0, killed $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %0:gr32 = PHI %4:gr32, %bb.0, %3:gr32, %bb.2
  %1:gr32 = PHI %4:gr32, %bb.0, %2:gr32, %bb.2
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY killed $eax
  %2:gr32 = nsw ADD32rr killed %1:gr32(tied-def 0), killed %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 killed %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Eliminate PHI nodes for register allocation ***:
# Machine code for function main: NoPHIs, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  %10:gr32 = COPY %4:gr32
  %11:gr32 = COPY killed %4:gr32
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = AND32ri killed %2:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY killed %9:gr32
  RET 0, killed $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %1:gr32 = COPY killed %11:gr32
  %0:gr32 = COPY killed %10:gr32
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY killed $eax
  %2:gr32 = nsw ADD32rr killed %1:gr32(tied-def 0), killed %5:gr32, implicit-def dead $eflags
  %3:gr32 = nuw nsw ADD32ri8 killed %0:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  %10:gr32 = COPY killed %3:gr32
  %11:gr32 = COPY %2:gr32
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Two-Address instruction pass ***:
# Machine code for function main: NoPHIs, TracksLiveness

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  %4:gr32 = MOV32r0 implicit-def dead $eflags
  %10:gr32 = COPY %4:gr32
  %11:gr32 = COPY killed %4:gr32
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2

  %7:gr32 = COPY killed %2:gr32
  %7:gr32 = AND32ri %7:gr32(tied-def 0), 4097, implicit-def dead $eflags
  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $eax = COPY killed %9:gr32
  RET 0, killed $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

  %1:gr32 = COPY killed %11:gr32
  %0:gr32 = COPY killed %10:gr32
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY %0:gr32
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  %5:gr32 = COPY killed $eax
  %2:gr32 = COPY killed %1:gr32
  %2:gr32 = nsw ADD32rr %2:gr32(tied-def 0), killed %5:gr32, implicit-def dead $eflags
  %3:gr32 = COPY killed %0:gr32
  %3:gr32 = nuw nsw ADD32ri8 %3:gr32(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri %3:gr32, 100000, implicit-def $eflags
  %10:gr32 = COPY killed %3:gr32
  %11:gr32 = COPY %2:gr32
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Slot index numbering ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %4:gr32 = MOV32r0 implicit-def dead $eflags
32B	  %10:gr32 = COPY %4:gr32
48B	  %11:gr32 = COPY killed %4:gr32
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

96B	  %7:gr32 = COPY killed %2:gr32
112B	  %7:gr32 = AND32ri %7:gr32(tied-def 0), 4097, implicit-def dead $eflags
128B	  %8:gr64_nosp = SUBREG_TO_REG 0, killed %7:gr32, %subreg.sub_32bit
144B	  %9:gr32 = MOV32rm $noreg, 4, killed %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY killed %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

208B	  %1:gr32 = COPY killed %11:gr32
224B	  %0:gr32 = COPY killed %10:gr32
240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %0:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
320B	  %2:gr32 = COPY killed %1:gr32
336B	  %2:gr32 = nsw ADD32rr %2:gr32(tied-def 0), killed %5:gr32, implicit-def dead $eflags
352B	  %3:gr32 = COPY killed %0:gr32
368B	  %3:gr32 = nuw nsw ADD32ri8 %3:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %3:gr32, 100000, implicit-def $eflags
400B	  %10:gr32 = COPY killed %3:gr32
416B	  %11:gr32 = COPY %2:gr32
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Live Interval Analysis ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %4:gr32 = MOV32r0 implicit-def dead $eflags
32B	  %10:gr32 = COPY %4:gr32
48B	  %11:gr32 = COPY %4:gr32
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

96B	  %7:gr32 = COPY %2:gr32
112B	  %7:gr32 = AND32ri %7:gr32(tied-def 0), 4097, implicit-def dead $eflags
128B	  %8:gr64_nosp = SUBREG_TO_REG 0, %7:gr32, %subreg.sub_32bit
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

208B	  %1:gr32 = COPY %11:gr32
224B	  %0:gr32 = COPY %10:gr32
240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %0:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
320B	  %2:gr32 = COPY %1:gr32
336B	  %2:gr32 = nsw ADD32rr %2:gr32(tied-def 0), %5:gr32, implicit-def dead $eflags
352B	  %3:gr32 = COPY %0:gr32
368B	  %3:gr32 = nuw nsw ADD32ri8 %3:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %3:gr32, 100000, implicit-def $eflags
400B	  %10:gr32 = COPY %3:gr32
416B	  %11:gr32 = COPY %2:gr32
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Simple Register Coalescing ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Rename Disconnected Subregister Components ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Machine Instruction Scheduler ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Debug Variable Analysis ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Live Stack Slot Analysis ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Virtual Register Map ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Live Register Matrix ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, killed $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY killed $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Greedy Register Allocator ***:
# Machine code for function main: NoPHIs, TracksLiveness

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  %10:gr32 = MOV32r0 implicit-def dead $eflags
48B	  undef %8.sub_32bit:gr64_nosp = MOV32r0 implicit-def dead $eflags
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2

112B	  %8.sub_32bit:gr64_nosp = AND32ri %8.sub_32bit:gr64_nosp(tied-def 0), 4097, implicit-def dead $eflags
144B	  %9:gr32 = MOV32rm $noreg, 4, %8:gr64_nosp, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
160B	  $eax = COPY %9:gr32
176B	  RET 0, $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)

240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY %10:gr32
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
304B	  %5:gr32 = COPY $eax
336B	  %8.sub_32bit:gr64_nosp = nsw ADD32rr %8.sub_32bit:gr64_nosp(tied-def 0), %5:gr32, implicit-def dead $eflags
368B	  %10:gr32 = nuw nsw ADD32ri8 %10:gr32(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri %10:gr32, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Virtual Register Rewriter ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  renamable $ebx = MOV32r0 implicit-def dead $eflags
48B	  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2
	  liveins: $r14
112B	  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
144B	  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
176B	  RET 0, $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
	  liveins: $ebx, $r14
240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY renamable $ebx
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
336B	  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
368B	  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri renamable $ebx, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Stack Slot Coloring ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

0B	bb.0.entry:
	  successors: %bb.2(0x80000000); %bb.2(100.00%)

16B	  renamable $ebx = MOV32r0 implicit-def dead $eflags
48B	  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
64B	  JMP_1 %bb.2

80B	bb.1.for.cond.cleanup:
	; predecessors: %bb.2
	  liveins: $r14
112B	  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
144B	  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
176B	  RET 0, $eax

192B	bb.2.for.body:
	; predecessors: %bb.0, %bb.2
	  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
	  liveins: $ebx, $r14
240B	  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
256B	  $edi = COPY renamable $ebx
272B	  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
288B	  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
336B	  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
368B	  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
384B	  CMP32ri renamable $ebx, 100000, implicit-def $eflags
432B	  JCC_1 %bb.1, 4, implicit killed $eflags
448B	  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Machine Copy Propagation Pass ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
  liveins: $ebx, $r14
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Machine Loop Invariant Code Motion ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
  liveins: $ebx, $r14
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After X86 FP Stackifier ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
  liveins: $ebx, $r14
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After PostRA Machine Sink ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
  liveins: $ebx, $r14
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Shrink Wrapping analysis ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)

  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
  liveins: $ebx, $r14
  ADJCALLSTACKDOWN64 0, 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  ADJCALLSTACKUP64 0, 0, implicit-def dead $rsp, implicit-def dead $eflags, implicit-def dead $ssp, implicit $rsp, implicit $ssp
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Prologue/Epilogue Insertion & Frame Finalization ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.2(0x80000000); %bb.2(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14
  JMP_1 %bb.2

bb.1.for.cond.cleanup:
; predecessors: %bb.2
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RET 0, $eax

bb.2.for.body:
; predecessors: %bb.0, %bb.2
  successors: %bb.1(0x04000000), %bb.2(0x7c000000); %bb.1(3.12%), %bb.2(96.88%)
  liveins: $ebx, $r14
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 4, implicit killed $eflags
  JMP_1 %bb.2

# End machine code for function main.

# *** IR Dump After Control Flow Optimizer ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RET 0, $eax

# End machine code for function main.

# *** IR Dump After Tail Duplication ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RET 0, $eax

# End machine code for function main.

# *** IR Dump After Machine Copy Propagation Pass ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = MOV32r0 implicit-def dead $eflags
  renamable $r14d = MOV32r0 implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = COPY renamable $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RET 0, $eax

# End machine code for function main.

# *** IR Dump After Post-RA pseudo instruction expansion pass ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RET 0, $eax

# End machine code for function main.

# *** IR Dump After X86 pseudo instruction expansion pass ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Post RA top-down list latency scheduler ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Analyze Machine Code For Garbage Collection ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body:
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Branch Probability Basic Block Placement ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After X86 Execution Dependency Fix ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After BreakFalseDeps ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After X86 Byte/Word Instruction Fixup ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After X86 LEA Fixup ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Compressing EVEX instrs to VEX encoding when possible ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Contiguously Lay Out Funclets ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After StackMap Liveness Analysis ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Live DEBUG_VALUE analysis ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Insert fentry calls ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Insert XRay ops ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Implement the 'patchable-function' attribute ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

# *** IR Dump After Check CFA info and insert CFI instructions if needed ***:
# Machine code for function main: NoPHIs, TracksLiveness, NoVRegs
Frame Objects:
  fi#-2: size=8, align=8, fixed, at location [SP-16]
  fi#-1: size=8, align=16, fixed, at location [SP-8]

bb.0.entry:
  successors: %bb.1(0x80000000); %bb.1(100.00%)
  liveins: $r14, $rbx
  frame-setup PUSH64r killed $r14, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  frame-setup PUSH64r killed $rbx, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 24
  frame-setup PUSH64r undef $rax, implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 32
  CFI_INSTRUCTION offset $rbx, -24
  CFI_INSTRUCTION offset $r14, -16
  renamable $ebx = XOR32rr undef $ebx(tied-def 0), undef $ebx, implicit-def dead $eflags
  renamable $r14d = XOR32rr undef $r14d(tied-def 0), undef $r14d, implicit-def dead $eflags, implicit-def $r14

bb.1.for.body (align 4):
; predecessors: %bb.0, %bb.1
  successors: %bb.2(0x04000000), %bb.1(0x7c000000); %bb.2(3.12%), %bb.1(96.88%)
  liveins: $ebx, $r14
  $edi = MOV32rr $ebx
  CALL64pcrel32 @workload, <regmask $bh $bl $bp $bph $bpl $bx $ebp $ebx $hbp $hbx $rbp $rbx $r12 $r13 $r14 $r15 $r12b $r13b $r14b $r15b $r12bh $r13bh $r14bh $r15bh $r12d $r13d $r14d $r15d $r12w $r13w $r14w $r15w $r12wh and 3 more...>, implicit $rsp, implicit $ssp, implicit killed $edi, implicit-def $rsp, implicit-def $ssp, implicit-def $eax
  renamable $r14d = nsw ADD32rr renamable $r14d(tied-def 0), killed renamable $eax, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $ebx = nuw nsw ADD32ri8 killed renamable $ebx(tied-def 0), 1, implicit-def dead $eflags
  CMP32ri renamable $ebx, 100000, implicit-def $eflags
  JCC_1 %bb.1, 5, implicit $eflags

bb.2.for.cond.cleanup:
; predecessors: %bb.1
  liveins: $r14
  renamable $r14d = AND32ri renamable $r14d(tied-def 0), 4097, implicit-def dead $eflags, implicit killed $r14, implicit-def $r14
  renamable $eax = MOV32rm $noreg, 4, killed renamable $r14, @arr, $noreg :: (load 4 from %ir.arrayidx, !tbaa !2)
  $rsp = frame-destroy ADD64ri8 $rsp(tied-def 0), 8, implicit-def dead $eflags
  CFI_INSTRUCTION def_cfa_offset 24
  $rbx = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 16
  $r14 = frame-destroy POP64r implicit-def $rsp, implicit $rsp
  CFI_INSTRUCTION def_cfa_offset 8
  RETQ $eax

# End machine code for function main.

